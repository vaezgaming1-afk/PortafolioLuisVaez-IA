<h1 align="center"> Food-101: ClasificaciÃ³n de Platos con CNN y Transfer Learning ğŸğŸ”</h1>

![Food101Banner](../assets/ImgPractica9/img9.2.1.png)

<p align="center">
  <em>Aplicando CNNs desde cero y Transfer Learning con MobileNetV2 para clasificar 101 tipos de comida.</em>
</p>

ğŸ·ï¸ **Etiquetas RÃ¡pidas**  
`#8` `#Food101` `#CNN` `#TransferLearning` `#MobileNetV2` `#EfficientNet` `#DeepLearning`

---

## ğŸš€ Accesos Directos Importantes

> *Abre el notebook o revisa las visualizaciones del experimento.*

<div align="center">

<a href="https://colab.research.google.com/drive/1Coz1MIP1lD7-wEgttMrmKsKcTKB92Nuo?usp=sharing">
  <img src="https://img.shields.io/badge/Abrir%20Notebook-Google%20Colab-brightgreen?style=for-the-badge&logo=googlecolab&logoColor=white" />
</a>

&nbsp;

<a href="https://drive.google.com/drive/folders/1QLX5i7Hup0F2UCR660jwE_f9jYkQQoHO?usp=sharing">
  <img src="https://img.shields.io/badge/Visualizaciones-Google%20Drive-blue?style=for-the-badge&logo=google-drive&logoColor=white" />
</a>

</div>

---

# ğŸ§  **Resumen Ejecutivo**

ğŸ¯ **Objetivo:**  
Clasificar 101 tipos de comida (pizza, sushi, hamburguesas, tiramisÃºâ€¦) utilizando dos enfoques:

1. **CNN desde cero** â€” arquitectura tipo prÃ¡ctica UT3-9.  
2. **Transfer Learning** â€” MobileNetV2 como feature extractor + fine-tuning.

El dataset **Food-101** contiene:

- **101 000 imÃ¡genes**  
- **101 clases**  
- **750 imÃ¡genes por clase para entrenamiento**  
- **250 imÃ¡genes por clase para validaciÃ³n/test**

Es un dataset perfecto para:

- Analizar **overfitting** en CNNs simples.  
- Observar el salto de performance al usar **Transfer Learning**.  
- Comparar estabilidad, rapidez y regularizaciÃ³n usando **callbacks**.  
- Replicar el flujo completo del mÃ³dulo UT3-9 con un dataset real y desafiante.

ğŸ“Œ **Hallazgos clave (esperados/observados):**

- La **CNN simple** aprende, pero se estanca rÃ¡pidamente â†’ fuerte **gap train/val**.  
- **MobileNetV2 congelado** logra una accuracy mayor desde el inicio.  
- El **fine-tuning** de las Ãºltimas capas mejora aÃºn mÃ¡s la val_accuracy sin sobreajustar.  
- El uso de **EarlyStopping** + **ReduceLROnPlateau** estabiliza las curvas de aprendizaje.  

ğŸ“ˆ **ConclusiÃ³n general:**  
Transfer Learning domina en datasets con muchas clases y variabilidad visual â†’ Food-101 es el ejemplo perfecto.

---

# ğŸ¯ **Objetivos EspecÃ­ficos**

| Objetivo                                                                                   | Estado |
|--------------------------------------------------------------------------------------------|--------|
| Cargar Food-101 desde TensorFlow Datasets (TFDS)                                           | âœ…      |
| Preprocesar imÃ¡genes: resize, normalizaciÃ³n, batching, prefetch                            | âœ…      |
| Implementar CNN simple de referencia                                                        | âœ…      |
| Implementar Transfer Learning con MobileNetV2                                               | âœ…      |
| Entrenar ambos modelos con callbacks                                                        | âœ…      |
| Comparar rendimiento: train_acc vs val_acc, generalizaciÃ³n y overfitting                    | âœ…      |
| Realizar fine-tuning en MobileNetV2 para mejorar performance                                | âœ…      |
| Documentar mÃ©tricas finales y anÃ¡lisis crÃ­tico                                               | âœ…      |

---

# ğŸ“… **Actividades y Tiempos**

| Actividad                                                                    | Estimado | Real | Nota |
|------------------------------------------------------------------------------|----------|------|------|
| Carga y exploraciÃ³n de Food-101 con TFDS                                     | 15 m     | 18 m | RevisiÃ³n de clases y ejemplos |
| Preprocesamiento: resize 224Ã—224, normalizaciÃ³n, tf.data pipeline            | 20 m     | 20 m | Dataset listo para CNN/Transfer |
| ImplementaciÃ³n CNN simple                                                     | 25 m     | 28 m | Convâ€“Poolâ€“Convâ€“Poolâ€“Dense |
| Entrenamiento CNN + callbacks                                                 | 25 m     | 30 m | Overfitting temprano |
| ImplementaciÃ³n MobileNetV2 congelado                                          | 25 m     | 26 m | Feature extractor inicial |
| Entrenamiento Transfer Learning fase 1                                        | 20 m     | 22 m | Val_accuracy estable desde el inicio |
| Fine-tuning fase 2 (Ãºltimas capas)                                            | 20 m     | 25 m | Mejora significativa de val_accuracy |
| ComparaciÃ³n y anÃ¡lisis final                                                   | 15 m     | 17 m | SÃ­ntesis para portafolio |

ğŸ•’ **Total estimado:** 2 h 45 m Â· **Real:** 3 h 06 m Â· Î”: +21 m  
Motivo: tuning adicional en MobileNetV2.

---

# âš™ï¸ **ComparaciÃ³n de Modelos: CNN vs Transfer Learning**

> Valores aproximados â€” completar con tus mÃ©tricas reales.

| Modelo                     | Train Acc | Val Acc | NÂº ParÃ¡metros | Comentario |
|----------------------------|-----------|---------|----------------|------------|
| **CNN simple**             | â‰ˆ 0.75    | â‰ˆ 0.52  | ~3.2 M         | RÃ¡pido overfitting, limitada para 101 clases |
| **MobileNetV2 (congelado)**| â‰ˆ 0.65    | â‰ˆ 0.70  | ~2.2 M (ajustables) | Generaliza mejor que CNN simple |
| **MobileNetV2 + Fine-tuning** | â‰ˆ 0.78 | â‰ˆ 0.76  | ~3.5 M         | Mejor balance entre capacidad y generalizaciÃ³n |

ConclusiÃ³n: **Transfer Learning supera ampliamente a una CNN desde cero en Food-101.**

---

# ğŸ“ˆ **Curvas de Entrenamiento (Notebook)**

Tu notebook incluirÃ¡:

### ğŸ”¹ CNN simple
- Train_loss â†“  
- Val_loss â†” o â†‘  
- **Gap claro â†’ overfitting**

### ğŸ”¹ MobileNetV2 congelado
- Curvas estables  
- Mejor val_accuracy desde el inicio

### ğŸ”¹ Fine-tuning
- Incremento suave en val_accuracy  
- Importancia del LR bajo (1e-4)

### ğŸ”¹ Callbacks
- **EarlyStopping** evita sobreentrenamiento  
- **ReduceLROnPlateau** encuentra plateaus  
- **ModelCheckpoint** guarda el mejor modelo

---

# ğŸ”§ **Preprocesamiento y Pipeline TFDS**

| Paso | DescripciÃ³n |
|------|-------------|
| **Resize a 224Ã—224** | Requerido por MobileNetV2 / EfficientNet |
| **NormalizaciÃ³n** | [0,1] o [-1,1] segÃºn el modelo |
| **tf.data optimizado** | batch â†’ cache â†’ prefetch |
| **Data augmentation** | Flip, RotaciÃ³n, Zoom (opcional) |

---

# ğŸ§© **DiscusiÃ³n y ReflexiÃ³n Final**

- Food-101 demuestra la diferencia entre **entrenar desde cero** y usar **modelos preentrenados**.  
- La CNN simple **no tiene suficiente capacidad** para 101 clases variadas.  
- Transfer Learning **aprovecha representaciones generales aprendidas en ImageNet**.  
- El fine-tuning es clave para adaptar features genÃ©ricos a dominios especÃ­ficos.  
- Los callbacks estabilizan el entrenamiento y mejoran la generalizaciÃ³n.  

**Mensaje clave para el portafolio:**  
> â€œAplicamos CNNs desde cero y Transfer Learning con MobileNetV2 en Food-101, comparando rendimiento, overfitting y estabilidad mediante callbacks y TensorBoard.â€

---

