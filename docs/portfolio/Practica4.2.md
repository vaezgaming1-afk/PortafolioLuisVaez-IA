<h1 align="center"> Prediciendo diagnosticos de Cancer de mama ğŸ“ˆ</h1>

![Banner](../assets/ImgPractica4/img4.2.1.png)

<p align="center">
  <em>ClasificaciÃ³n de tumores (Maligno vs Benigno) y estimaciÃ³n del tamaÃ±o crÃ­tico</em>
</p>


ğŸ·ï¸ **Etiquetas**  
`#RegresiÃ³nLineal` `#RegresiÃ³nLogÃ­stica` `#MachineLearning` `#Adversiting` `#ModeloBase` 


## ğŸš€ Accesos Directos Importantes

> *Haz clic en los botones para abrir el notebook y explorar las visualizaciones interactivas.*

<div align="center">

<a href="https://colab.research.google.com/drive/1mGZcRBJ4sf_1nQk62vVReCx_b7CpJS3v?usp=sharing">
  <img src="https://img.shields.io/badge/Abrir%20Notebook-Google%20Colab-brightgreen?style=for-the-badge&logo=googlecolab&logoColor=white" alt="Abrir en Colab" />
</a>
&nbsp;
<a href="https://drive.google.com/drive/folders/1wOUvueAO5j6l3XfcjE0lRyDTBlaRZ8L6?usp=sharing">
  <img src="https://img.shields.io/badge/Visualizaciones-Google%20Drive-blue?style=for-the-badge&logo=google-drive&logoColor=white" alt="Ver en Drive" />
</a>

</div>

## ğŸ“ Resumen Ejecutivo

### ğŸ¯ Objetivo Principal

Transformar un anÃ¡lisis descriptivo del dataset de **CÃ¡ncer de Mama (Breast Cancer Wisconsin)**  
en **dos soluciones predictivas complementarias**:

1. Un modelo de **RegresiÃ³n LogÃ­stica** para **clasificar tumores como Malignos (0) o Benignos (1)**  
   y apoyar el **triage de biopsias**.
2. Un modelo de **RegresiÃ³n Lineal MÃºltiple** para **estimar el tamaÃ±o crÃ­tico del tumor (`worst area`)**,  
   entendido como una medida continua de **gravedad**.

El propÃ³sito es responder dos preguntas clÃ­nicas clave:

- **â€œÂ¿QuÃ© probabilidad tiene este tumor de ser maligno?â€** (RegresiÃ³n LogÃ­stica â€“ Triage)  
- **â€œÂ¿QuÃ© tan grande/agresiva podrÃ­a ser esta lesiÃ³n en su peor zona?â€** (RegresiÃ³n Lineal â€“ Gravedad continua)

---

### ğŸ“Œ Hallazgos Clave

> â€œNo todos los errores valen lo mismo: en oncologÃ­a, un falso negativo es un tumor invisible para el sistema.â€

- ğŸ§¬ **Alta capacidad de discriminaciÃ³n Maligno vs Benigno (LogÃ­stica):**  
  El modelo de RegresiÃ³n LogÃ­stica alcanza **buenas mÃ©tricas globales**  
  (Accuracy, F1, ROCâ€“AUC), pero el foco del anÃ¡lisis se centra en la  
  **sensibilidad para tumores malignos** y en identificar **Falsos Negativos**.

- ğŸš¨ **Autopsia de errores clÃ­nicos:**  
  A travÃ©s de la **matriz de confusiÃ³n** y un **mapa 2D (mean radius vs mean texture)**,  
  se localizaron los casos donde el modelo:
  - Clasifica **malignos como benignos** (Falsos Negativos â†’ riesgo clÃ­nico).
  - Clasifica **benignos como malignos** (Falsos Positivos â†’ sobre-alerta).
  Esto permite proponer reglas de triage como:  
  *â€œSi el modelo dice â€˜Benignoâ€™ pero el tumor cae en cierta regiÃ³n del plano morfolÃ³gico â†’ revisiÃ³n humana obligatoriaâ€.*

- ğŸ“ **EstimaciÃ³n de gravedad tumoral (`worst area`) con RegresiÃ³n Lineal:**  
  Usando features como `mean radius`, `mean perimeter`, `mean area`,  
  `mean concavity` y `mean concave points`, la RegresiÃ³n Lineal logra:
  - Explicar una fracciÃ³n significativa de la variabilidad de `worst area` (RÂ² razonable).
  - Errores medios (MAE / RMSE) aceptables para usar el modelo como **estimador preliminar**.

- ğŸ§± **Interpretabilidad de los coeficientes:**  
  En ambos casos:
  - La LogÃ­stica permite interpretar quÃ© variables **aumentan la probabilidad de benignidad/malignidad**.  
  - La Lineal muestra quÃ© parÃ¡metros morfolÃ³gicos **inflan mÃ¡s el tamaÃ±o crÃ­tico** del tumor.

> ğŸ’¡ Mensaje central:  
> Los modelos no reemplazan al mÃ©dico, pero entregan **probabilidades y estimaciones cuantitativas**  
> que ayudan a priorizar, entender patrones y diseÃ±ar polÃ­ticas de triage mÃ¡s seguras.

---

## ğŸ“¦ Ficha TÃ©cnica del Dataset

- **Nombre:** Breast Cancer Wisconsin (Diagnostic)  
- **Fuente:** `sklearn.datasets.load_breast_cancer()`  
- **Dimensiones:**  
  - ~569 observaciones (tumores)  
  - ~30 variables numÃ©ricas de caracterÃ­sticas morfolÃ³gicas

### ğŸ”¢ Variables Relevantes

- **Target principal (clasificaciÃ³n):**
  - `target`:
    - `0` â†’ Maligno  
    - `1` â†’ Benigno

- **Subset de features usadas (ejemplos):**
  - `mean radius`, `mean texture`, `mean perimeter`, `mean area`  
  - `mean compactness`, `mean concavity`, `mean concave points`  
  - `worst area`, `worst radius`, etc.

- **Target de regresiÃ³n (gravedad continua):**
  - `worst area` â†’ Ã¡rea del tumor en su regiÃ³n mÃ¡s crÃ­tica (medida continua).

---

## ğŸ“Š GestiÃ³n del Proyecto

### âœ… Checklist de Objetivos

| Tarea                                                                 | Estado |
|---------------------------------------------------------------------|--------|
| ğŸ“¥ Carga del dataset Breast Cancer y creaciÃ³n de `df_bc`             | â˜‘ï¸     |
| ğŸ” ExploraciÃ³n inicial de variables (shape, tipos, estadÃ­sticas)     | â˜‘ï¸     |
| ğŸ§ª **Caso 1 â€“ LogÃ­stica:** definiciÃ³n del problema Maligno vs Benigno | â˜‘ï¸     |
| ğŸ§® Entrenamiento de RegresiÃ³n LogÃ­stica (train/test estratificado)   | â˜‘ï¸     |
| ğŸ“Š Dashboard de clasificaciÃ³n (matriz de confusiÃ³n, ROC, histograma de probabilidades, mapa 2D de errores) | â˜‘ï¸ |
| ğŸ§© â€œAutopsia de erroresâ€: anÃ¡lisis de Falsos Positivos y Falsos Negativos | â˜‘ï¸ |
| ğŸ“ **Caso 2 â€“ Lineal:** definiciÃ³n del problema `worst area` como variable continua | â˜‘ï¸ |
| ğŸ§® Entrenamiento de RegresiÃ³n Lineal MÃºltiple                        | â˜‘ï¸     |
| ğŸ“‰ Dashboard de regresiÃ³n (reales vs predichas, residuos, histograma, coeficientes) | â˜‘ï¸ |
| ğŸ“ RedacciÃ³n de interpretaciones clÃ­nicas y resumen ejecutivo        | â˜‘ï¸     |

---

### â° Cronograma: CÃ¡ncer de Mama â€“ Modelos de DiagnÃ³stico y Gravedad


| Actividad                                                 | â±ï¸ Estimado | â° Real | ğŸ“ Notas                                    |
|----------------------------------------------------------|------------:|-------:|--------------------------------------------|
| Carga del dataset y EDA bÃ¡sico                           | 20 m        | 20 m   | RevisiÃ³n de dimensiones y variables clave. |
| Caso 1: DefiniciÃ³n del problema de clasificaciÃ³n         | 15 m        | 18 m   | Planteo clÃ­nico: Maligno vs Benigno.       |
| Entrenamiento de RegresiÃ³n LogÃ­stica + mÃ©tricas          | 30 m        | 32 m   | Incluye funciÃ³n de evaluaciÃ³n personalizada. |
| Dashboard de clasificaciÃ³n + autopsia de errores         | 35 m        | 38 m   | Matriz de confusiÃ³n, ROC, histogramas, mapa 2D. |
| Caso 2: DefiniciÃ³n del problema de regresiÃ³n (`worst area`)| 15 m      | 15 m   | SelecciÃ³n de features morfolÃ³gicas bÃ¡sicas. |
| Entrenamiento de RegresiÃ³n Lineal + mÃ©tricas             | 30 m        | 33 m   | EvaluaciÃ³n con MAE, RMSE, RÂ².              |
| Dashboard de regresiÃ³n (diagnÃ³stico visual)              | 30 m        | 35 m   | GrÃ¡ficos de residuos y coeficientes.       |
| RedacciÃ³n de interpretaciÃ³n clÃ­nica y resumen general    | 25 m        | 27 m   | Enfoque en triage y gravedad tumoral.      |
| **TOTAL**                                                | **3h 10m**  | **3h 38m** | ğŸ”¼ +28 m (mayor detalle en dashboards e interpretaciÃ³n). |

---

## ğŸ“š Diccionario de Datos Clave

| Variable             | Tipo      | Unidad     | Rol / DescripciÃ³n                                                 |
|----------------------|-----------|------------|-------------------------------------------------------------------|
| `target`             | Binaria   | 0 / 1      | Variable de clasificaciÃ³n: 0 = Maligno, 1 = Benigno.             |
| `diagnosis_label`    | CategÃ³rica| texto      | VersiÃ³n legible: â€œMalignoâ€ / â€œBenignoâ€.                          |
| `mean radius`        | NumÃ©rica  | unidad relativa | Radio promedio del tumor.                                    |
| `mean perimeter`     | NumÃ©rica  | unidad relativa | PerÃ­metro promedio.                                          |
| `mean area`          | NumÃ©rica  | unidad relativa | Ãrea promedio.                                               |
| `mean concavity`     | NumÃ©rica  | adimensional | Grado de concavidad promedio de los contornos.              |
| `mean concave points`| NumÃ©rica  | adimensional | Puntos cÃ³ncavos en los bordes (irregularidad).              |
| `worst area`         | NumÃ©rica  | unidad relativa | **Target de regresiÃ³n:** Ã¡rea crÃ­tica en la porciÃ³n mÃ¡s â€œgraveâ€ del tumor. |
| `proba_maligno`      | NumÃ©rica  | 0â€“1        | Probabilidad predicha de que el tumor sea maligno (P(y=0)).      |

---

## ğŸ” AnÃ¡lisis Detallado de Resultados

### 1. Caso 1 â€“ RegresiÃ³n LogÃ­stica: Triage de Biopsias

- **Capacidad discriminativa:**  
  El modelo de RegresiÃ³n LogÃ­stica logra separar de forma consistente tumores **Malignos** y **Benignos**:
  - MÃ©tricas como **Accuracy**, **Recall**, **F1** y **ROCâ€“AUC** muestran un buen rendimiento global.
  - La **ROC** se mantiene claramente por encima de la diagonal aleatoria, lo que indica que el modelo puede ajustar umbrales segÃºn la polÃ­tica clÃ­nica (mÃ¡s o menos conservadora).

- **Autopsia de errores:**  
  El anÃ¡lisis no se quedÃ³ en los promedios:
  - La **matriz de confusiÃ³n** permitiÃ³ identificar cuÃ¡ntos tumores malignos se estÃ¡n clasificando errÃ³neamente como benignos (**Falsos Negativos**), el error mÃ¡s peligroso.
  - El **mapa 2D (`mean radius` vs `mean texture`)** mostrÃ³ dÃ³nde se concentran los errores:
    - Puntos marcados como:
      - âŒ Falsos Negativos (Maligno â†’ Benigno)  
      - â—† Falsos Positivos (Benigno â†’ Maligno)

- **Probabilidades y umbrales de triage:**  
  El histograma de **probabilidades de malignidad** por clase real permite:
  - Analizar si el umbral estÃ¡ndar de 0.5 deja malignos del lado â€œseguroâ€.  
  - Proponer umbrales mÃ¡s agresivos (ej. 0.4 o 0.3) para reducir falsos negativos, a costa de mÃ¡s falsos positivos.

> ğŸ’¡ ConclusiÃ³n Caso 1:  
> La RegresiÃ³n LogÃ­stica funciona como un **filtro de riesgo**:  
#### ğŸ” 1. AnÃ¡lisis de DistribuciÃ³n (Histogramas)
* **Zona de Seguridad:** Si el `mean radius` es menor a **10**, la probabilidad de que el tumor sea Benigno (naranja) es casi total.
* **Zona de Alerta:** Si el radio supera los **18-20**, la distribuciÃ³n es casi exclusivamente Maligna (azul).
* **Zona de Conflicto:** Entre los valores **12 y 16**, las curvas naranja y azul se solapan significativamente. AquÃ­ es donde el modelo matemÃ¡tico sufrirÃ¡ mÃ¡s y donde se requiere el "filtro" probabilÃ­stico.

#### ğŸ“‰ 2. JerarquÃ­a de Variables (CorrelaciÃ³n)
El grÃ¡fico de barras revela los mejores predictores. Curiosamente, el **radio** no es el Ãºnico factor determinante:
* **MorfologÃ­a Irregular:** Variables como `worst concave points` (puntos cÃ³ncavos) y `worst perimeter` tienen correlaciones extremadamente fuertes (cerca de **-0.8** con el target).
* **InterpretaciÃ³n:** La forma irregular y los bordes del tumor son tan o mÃ¡s importantes que el tamaÃ±o puro para el diagnÃ³stico.

---

### 2. Caso 2 â€“ RegresiÃ³n Lineal: Gravedad Continua a travÃ©s de `worst area`

- **Capacidad explicativa (RÂ²) y errores (MAE, RMSE):**  
  El modelo de RegresiÃ³n Lineal MÃºltiple usando `mean radius`, `mean perimeter`,  
  `mean area`, `mean compactness`, `mean concavity` y `mean concave points`:

  - Consigue un **RÂ² razonable**, lo que indica que estas features explican buena parte  
    de la variaciÃ³n en `worst area`.
  - Los valores de **MAE** y **RMSE** se mantienen en un rango aceptable para usar el modelo como  
    **estimador preliminar** (no como medida definitiva).

- **DiagnÃ³stico visual del ajuste:**
  - El grÃ¡fico de **`worst area` real vs predicho** muestra un alineamiento razonable alrededor de la diagonal â†’ el modelo captura la tendencia general del tamaÃ±o crÃ­tico.
  - El grÃ¡fico de **residuos vs predicciÃ³n** no evidencia patrones curvos muy fuertes:
    - Los errores se distribuyen alrededor de 0 sin estructura dominante,
      lo cual es compatible con una relaciÃ³n aproximadamente lineal.
  - El **histograma de residuos** estÃ¡ centrado cerca de 0, sin colas extremas exageradas.

- **Coeficientes Î² como â€œfactores de gravedadâ€:**
  - Features como `mean area`, `mean radius` y `mean perimeter` suelen tener coeficientes positivos altos,
    indicando que:
    - Tumores con mayor tamaÃ±o promedio tienden a tener un `worst area` mÃ¡s elevado.
  - La presencia de altas `mean concavity` y `mean concave points` refuerza la idea de que
    la **irregularidad de la forma** tambiÃ©n incrementa la gravedad.

> ğŸ’¡ ConclusiÃ³n Caso 2: 
#### ğŸ“Š Capacidad explicativa y precisiÃ³n (RÂ², MAE, RMSE)
El modelo de RegresiÃ³n Lineal MÃºltiple â€”usando `mean radius`, `perimeter`, `area`, `compactness` y `concavity`â€” revela:

* **Poder Predictivo:** Consigue un **RÂ² razonable**, indicando que estas features explican gran parte de la variaciÃ³n en el tamaÃ±o crÃ­tico (`worst area`).
* **Margen de Error:** Los valores de **MAE** y **RMSE** son aceptables, validando al modelo como un **estimador preliminar** confiable (Ãºtil para dimensionar el problema, aunque no como medida clÃ­nica definitiva).

#### ğŸ“‰ DiagnÃ³stico visual del ajuste
* **Realidad vs. PredicciÃ³n:** El alineamiento alrededor de la diagonal confirma que el modelo captura la tendencia general del tamaÃ±o.
* **Salud de los Residuos:**
    * Los errores se distribuyen alrededor de 0 sin patrones curvos fuertes, lo que es compatible con una relaciÃ³n lineal.
    * El histograma de residuos estÃ¡ centrado, sin colas extremas que sugieran anomalÃ­as graves.

---

### ğŸ§© VisiÃ³n Integrada de Ambos Casos

- **RegresiÃ³n LogÃ­stica (Caso 1):**  
  â†’ responde **â€œÂ¿Es probable que este tumor sea maligno?â€** y ayuda a diseÃ±ar un **sistema de triage**.

- **RegresiÃ³n Lineal (Caso 2):**  
  â†’ responde **â€œÂ¿QuÃ© tan grande/agresiva podrÃ­a ser la lesiÃ³n en su peor zona?â€**  
     y ofrece una **medida continua de gravedad**.

> Juntos, los dos modelos convierten el dataset de cÃ¡ncer de mama en una herramienta didÃ¡ctica y clÃ­nica:
> - Un **semÃ¡foro de riesgo** (LogÃ­stica)  
> - y una **regla cuantitativa de gravedad** (Lineal)  
> que, usados con criterio mÃ©dico, pueden mejorar la priorizaciÃ³n y comprensiÃ³n de los casos oncolÃ³gicos.

## ğŸ“¸ VisualizaciÃ³n Clave

Este proyecto puede resumirse visualmente con:

- **A. Esquema anatÃ³mico (izquierda):**  
  Muestra la diferencia estructural entre un **tumor benigno** y uno **maligno**  
  (organizaciÃ³n de cÃ©lulas, invasiÃ³n del tejido sano).

- **B. Panel de mamografÃ­as (derecha):**  
  Una cuadrÃ­cula que contrasta ejemplos **benignos** (marco verde) y  
  **malignos** (marco rojo), resaltando cambios en textura, bordes y densidad  
  que el modelo debe aprender a distinguir.

![Matriz de correlacion](../assets/ImgPractica4/img4.2.2.png)

## ğŸ”„ **DESAFIOS DIRECTOS CON EL DATASET**

InstalaciÃ³n rÃ¡pida:

```bash
pip install -q pandas seaborn scikit-learn matplotlib
```

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(7, 5))

plt.hist(
    proba_maligno[y_bc_test == 0],
    bins=15,
    alpha=0.7,
    label="Real: Maligno (0)"
)
plt.hist(
    proba_maligno[y_bc_test == 1],
    bins=15,
    alpha=0.7,
    label="Real: Benigno (1)"
)

plt.axvline(0.5, color="red", linestyle="--", label="Umbral 0.5")
plt.xlabel("Probabilidad predicha de ser Maligno (P(y=0))")
plt.ylabel("Frecuencia")
plt.title("DistribuciÃ³n de probabilidades de malignidad\npor clase real (Test)")
plt.legend()
plt.tight_layout()
plt.show()
```

![viewdatoss](../assets/ImgPractica4/img4.2.3.png)

## ğŸ“Š Relaciones Clave del Tumor: RadiografÃ­a del Comportamiento Celular

Antes de entrenar cualquier modelo, es esencial entender **cÃ³mo se relacionan las caracterÃ­sticas fÃ­sicas del tumor** con el diagnÃ³stico final  
(**Benigno** vs **Maligno**).  

Este panel de dispersiÃ³n â€”usando *Mean Radius*, *Mean Texture* y *Mean Smoothness*â€” permite detectar:

- **Patrones de separabilidad claros**, donde los tumores malignos presentan tamaÃ±os mayores e irregularidad marcada.
- **Variables altamente informativas**, cuyas escalas muestran agrupaciones definidas entre ambas clases.
- **Regiones de solapamiento**, donde benignos y malignos comparten valores similares, revelando quÃ© partes del espacio de datos requieren modelos mÃ¡s robustos.

AdemÃ¡s, este grÃ¡fico facilita comparar visualmente:

- ğŸ”´ **Malignos**: valores mÃ¡s altos en radio y textura, con mayor dispersiÃ³n e irregularidad.  
- ğŸŸ¢ **Benignos**: masas mÃ¡s pequeÃ±as, homogÃ©neas y de bordes mÃ¡s uniformes.  
- ğŸ›ï¸ **Smoothness (suavidad)**: una seÃ±al suave pero Ãºtil para distinguir estructuras finas del tejido.

Este grÃ¡fico responde a una pregunta esencial:

> **Â¿Las caracterÃ­sticas geomÃ©tricas y texturales del tumor permiten distinguir con claridad  
> entre lesiones benignas y malignas, o existen zonas grises donde ambos se mezclan?**

A continuaciÃ³n se genera el panel de dispersiÃ³n que contrasta  
`mean radius`, `mean texture` y `mean smoothness` frente al diagnÃ³stico.

![view4.1.5](../assets/ImgPractica4/img4.2.4.png)

### ğŸ“Š InterpretaciÃ³n del GrÃ¡fico: Â¿CÃ³mo se diferencian los tumores benignos y malignos?

Este grÃ¡fico responde a una pregunta esencial:

> **Â¿Existen biomarcadores que separen claramente tumores malignos y benignosâ€¦  
> o se requiere combinar mÃºltiples caracterÃ­sticas para lograr una clasificaciÃ³n precisa?**

---

#### ğŸ” Lecturas Clave del Panel de DispersiÃ³n

- **mean radius: el biomarcador mÃ¡s poderoso**  
  En el grÃ¡fico **Radius vs Perimeter**, los puntos rojos (malignos) se concentran en valores mÃ¡s altos de tamaÃ±o.  
  Esto revela que **los tumores malignos suelen ser mÃ¡s grandes**, y esta variable por sÃ­ sola ya ofrece una separaciÃ³n parcial muy clara.

- **mean smoothness: separaciÃ³n moderada, con mÃ¡s solapamiento**  
  En **Smoothness vs Perimeter**, aÃºn hay diferencia entre benignos y malignos,  
  pero la nube de puntos muestra zonas donde ambas clases se mezclan.  
  Esto indica que la suavidad **no es suficiente por sÃ­ sola** y debe combinarse con otras variables.

- **mean compactness: fuerte discriminaciÃ³n en los rangos altos**  
  En **Compactness vs Perimeter**, los valores altos (lado derecho) pertenecen casi exclusivamente a tumores malignos.  
  Esto sugiere que la **compactaciÃ³n del tejido** es un indicador clave de comportamiento agresivo.

---

# ğŸ•µï¸â€âš•ï¸ **Caso 1: El Dilema del â€œTumor Invisibleâ€**  

### **âš ï¸ SituaciÃ³n Detectada:**

He entrenado un modelo de **RegresiÃ³n LogÃ­stica** sobre el dataset **Breast Cancer Wisconsin**, con una **precisiÃ³n global cercana al 95%** al clasificar tumores como **Malignos (0)** o **Benignos (1)**.  
Sobre el papel suena excelente, pero en contexto clÃ­nico **no todos los errores valen lo mismo**:

- Un **Falso Positivo (FP)** â€” etiquetar un tumor benigno como maligno â€” implica:
  - Ansiedad y estrÃ©s para el paciente.  
  - Pruebas adicionales y biopsias invasivas potencialmente innecesarias.

- Un **Falso Negativo (FN)** â€” etiquetar un tumor maligno como benigno â€” implica:
  - No detectar un cÃ¡ncer a tiempo.  
  - Riesgo real de empeorar el pronÃ³stico y retrasar el tratamiento.

Ese ~5% de error no es simple ruido estadÃ­stico:  
son **vidas, decisiones clÃ­nicas y responsabilidad mÃ©dica**.  
Mi preocupaciÃ³n central es entender **en quÃ© tipo de tumores el modelo comete Falsos Negativos**, es decir, dÃ³nde estÃ¡ el verdadero **â€œtumor invisibleâ€** para la IA.

---

### **ğŸ¯ Objetivo de esta secciÃ³n:**

Realizar una **â€œAutopsia de Errores ClÃ­nicosâ€** para ir mÃ¡s allÃ¡ de la Accuracy y responder:

- **Â¿DÃ³nde y por quÃ© se equivoca el modelo con tumores malignos?**  
- **Â¿Existe un â€œPunto Ciegoâ€** (un rango especÃ­fico de tamaÃ±o, textura, concavidad, etc.) donde la IA **falla sistemÃ¡ticamente**?  
- **Â¿Podemos definir reglas de triage** del tipo:  
  > â€œSi el modelo dice *Benigno* pero el tumor cae en esta zona de riesgo â†’ requiere revisiÃ³n humana obligatoriaâ€?

Si logro identificar estos patrones de error, podrÃ© proponer **umbral clÃ­nicos y reglas de seguridad** como:

- â€œSi el modelo predice *Benigno* pero el `mean_radius` es muy alto â†’ **derivar siempre a revisiÃ³n mÃ©dica especializada**.â€  
- â€œSi la probabilidad de malignidad estÃ¡ cerca del umbral (zona gris) â†’ **no confiar solo en la IA, exigir segunda opiniÃ³n**.â€

---

### **CÃ¡lculo Previo: Autopsia de Errores del Modelo** ğŸ©ºğŸ“Š

> Este fragmento conceptual prepara el terreno para estudiar **dÃ³nde se equivoca la IA**:

> 1. **Define** las variables de entrada `X` (medidas del tumor: radios, texturas, concavidades, etc.) y la etiqueta `y` (0 = Maligno, 1 = Benigno).  
> 2. **Divide** el dataset en entrenamiento y prueba para evaluar al modelo en tumores â€œno vistosâ€.  
> 3. **Entrena** una **RegresiÃ³n LogÃ­stica** (idealmente con `class_weight` ajustado) para manejar el costo desigual de FN vs FP.  
> 4. **Calcula** la matriz de confusiÃ³n y **extrae explÃ­citamente** los Falsos Negativos.  
> 5. **Analiza** las caracterÃ­sticas de esos FNs (distribuciÃ³n de `mean_radius`, `mean_texture`, `mean_concavity`, etc.) para detectar el posible **â€œPunto Ciegoâ€ clÃ­nico** donde el modelo subestima tumores malignos.

```python hl_lines="11 12 15 16 17" linenums="1"
# --- 1. Features y Target ---
X = df_bc.drop(columns=["target", "diagnosis_label"])   # Variables del tumor
y = df_bc["target"]                                      # 0 = Maligno, 1 = Benigno

# --- 2. Split estratificado ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# --- 3. Entrenar Modelo (RegresiÃ³n LogÃ­stica) ---
model = LogisticRegression(solver="liblinear", max_iter=1000)
model.fit(X_train, y_train)

# --- 4. Predicciones y Probabilidades ---
proba = model.predict_proba(X_test)
proba_malig = proba[:, 0]        # P(y=0) = Maligno
y_pred = (proba[:, 1] >= 0.5).astype(int)

# --- 5. MÃ©tricas clave (globales) ---
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Recall Maligno:", recall_score(y_test, y_pred, pos_label=0))

# --- 6. Extraer Falsos Negativos (cÃ¡ncer que el modelo NO detectÃ³) ---
FN = ( (y_test == 0) & (y_pred == 1) )   # Real maligno â†’ predicho benigno
print("Falsos Negativos:", FN.sum())

# --- 7. Curva ROC para detectar malignos ---
RocCurveDisplay.from_predictions(y_test, proba_malig, pos_label=0)
plt.title("ROC â€“ DetecciÃ³n de tumores malignos")
plt.show()

```
![view4.1.6](../assets/ImgPractica4/img4.2.5.png)

### ğŸ“Š **DiagnÃ³stico ClÃ­nico del Modelo: Â¿DÃ³nde estÃ¡ fallando la IA?**

DespuÃ©s de entrenar el clasificador, no basta con ver la Accuracy.  
En medicina, lo crÃ­tico es detectar **cÃ³mo** y **dÃ³nde** se equivoca el modelo.

Este grÃ¡fico revela dos elementos esenciales para evaluar seguridad clÃ­nica:

#### ğŸ” 1. Mapa de Casos Reales: Benignos vs Malignos  
Cada punto representa un tumor segÃºn sus medidas **mean radius** y **mean texture**.  
Las dos nubes muestran cÃ³mo se distribuyen ambas clases en el plano clÃ­nico:

- ğŸŸ¦ **Malignos** â†’ valores mÃ¡s altos y dispersos.  
- ğŸŸ§ **Benignos** â†’ valores mÃ¡s bajos y agrupados.


#### ğŸ” 2. Los Errores CrÃ­ticos del Modelo  
Se resaltan en el grÃ¡fico:

- **âŒ Falsos Negativos (FN)** â€” marcados en **amarillo**  
  > Tumores malignos que la IA clasificÃ³ como benignos.  
  Estos son los *mÃ¡s peligrosos*, pues implican riesgo de no detectar un cÃ¡ncer.

- **âš ï¸ Falsos Positivos (FP)** â€” marcados en **rojo**  
  > Tumores benignos que la IA marcÃ³ como malignos.  
  Generan ansiedad y pruebas innecesarias, pero no comprometen el pronÃ³stico.

```python
# 1) Volvemos a construir las mÃ¡scaras de errores y aciertos
#    (por si esta celda se ejecuta sola)
correct_mask = (y_bc_test == y_bc_test_pred)

# Falso Negativo Maligno: Real = 0 (Maligno), Pred = 1 (Benigno)
fn_malig_mask = (y_bc_test == 0) & (y_bc_test_pred == 1)

# Falso Positivo Maligno: Real = 1 (Benigno), Pred = 0 (Maligno)
fp_malig_mask = (y_bc_test == 1) & (y_bc_test_pred == 0)

plt.figure(figsize=(7, 6))

# 2) Casos correctamente clasificados (como "fondo")
sns.scatterplot(
    x=X_bc_test.loc[correct_mask, "mean radius"],
    y=X_bc_test.loc[correct_mask, "mean texture"],
    hue=y_bc_test[correct_mask].map({0: "Maligno", 1: "Benigno"}),
    alpha=0.4,
    s=40
)

# 3) Falsos Negativos Malignos (puntos que mÃ¡s nos preocupan)
plt.scatter(
    X_bc_test.loc[fn_malig_mask, "mean radius"],
    X_bc_test.loc[fn_malig_mask, "mean texture"],
    edgecolor="black",
    facecolor="yellow",
    s=120,
    marker="X",
    label="Falsos Negativos (Malignos â†’ Benignos)"
)

# 4) Falsos Positivos Malignos
plt.scatter(
    X_bc_test.loc[fp_malig_mask, "mean radius"],
    X_bc_test.loc[fp_malig_mask, "mean texture"],
    edgecolor="black",
    facecolor="red",
    s=80,
    marker="D",
    label="Falsos Positivos (Benignos â†’ Malignos)"
)
```
![view4.1.7](../assets/ImgPractica4/img4.2.6.png)

### ğŸ©º DiagnÃ³stico del Modelo: Â¿QuÃ© tan confiable es la IA para apoyar decisiones clÃ­nicas?

Una vez entrenado el modelo de **RegresiÃ³n LogÃ­stica** para clasificar tumores como  
**Malignos (0)** o **Benignos (1)**, es indispensable evaluar no solo la precisiÃ³n global,  
sino **cÃ³mo se comporta el sistema en situaciones crÃ­ticas para el triage oncolÃ³gico**.

Este panel de cuatro visualizaciones responde a preguntas clÃ­nicas esenciales:

---

#### ğŸ”¬ 1. Matriz de ConfusiÃ³n â€” *Rendimiento Global del Modelo*  
Permite ver cuÃ¡ntos tumores fueron correctamente identificados y, sobre todo,  
si existen **Falsos Negativos (Malignos â†’ Benignos)**.  
Ese cuadrante es el mÃ¡s delicado, pues representa casos donde la IA â€œno vio el cÃ¡ncerâ€.

---

#### ğŸ“ˆ 2. Curva ROC â€” *Capacidad real de discriminaciÃ³n*  
Cuanto mÃ¡s se aleje la curva de la diagonal, mejor distingue la IA entre  
tumores malignos y benignos. Un **AUC alto** significa que el modelo consigue  
ordenar correctamente los casos segÃºn su probabilidad de malignidad.

---

#### ğŸ“Š 3. DistribuciÃ³n de Probabilidades â€” *Â¿Es seguro el umbral 0.5?*  
Este histograma muestra cÃ³mo separa el modelo las probabilidades de los dos grupos.  
Idealmente, los **malignos** estÃ¡n a la derecha (probabilidad alta)  
y los **benignos** a la izquierda.  
Si ambas distribuciones se mezclan cerca del umbral, la predicciÃ³n de la IA se vuelve incierta.

---

#### ğŸ—ºï¸ 4. Mapa ClÃ­nico de Errores â€” *Â¿DÃ³nde falla el modelo fÃ­sicamente?*  
GrÃ¡fico en el plano **mean radius vs mean texture** que marca:

- âœ”ï¸ casos bien clasificados (benignos y malignos)  
- âŒ **Falsos Negativos** (Malignos que el modelo llamÃ³ Benignos)  
- â— Falsos Positivos (Benignos que el modelo clasificÃ³ como Malignos)

Este panel revela si los errores del modelo se concentran en ciertos rangos  
de tamaÃ±o, textura o patrones atÃ­picos, lo que ayuda a definir **reglas de seguridad clÃ­nica**  
del tipo: â€œsi un tumor cae en esta zona â†’ revisiÃ³n mÃ©dica obligatoriaâ€.

---

En conjunto, este dashboard permite evaluar si el modelo es **clÃ­nicamente confiable**,  
detectando no solo su precisiÃ³n general sino tambiÃ©n sus **puntos ciegos** y  
sus implicancias reales en la prÃ¡ctica diagnÃ³stica.

![view4.1.7](../assets/ImgPractica4/img4.2.7.png)

### âš–ï¸ **Veredicto del Caso 1: El Dilema del â€œTumor Invisibleâ€**  

Tras analizar el rendimiento del modelo y descomponer sus errores, la evidencia es clara:

- El modelo logra una **alta precisiÃ³n global (~95%)**, pero esto **no garantiza seguridad clÃ­nica**.  
- Los **Falsos Negativos**, aunque pocos, representan el riesgo crÃ­tico:  
  tumores malignos que la IA clasifica como benignos.  
- La **Curva ROC** confirma que el modelo discrimina bien en general (AUC alto),  
  pero no elimina el peligro de casos que caen cerca del umbral.
- La **distribuciÃ³n de probabilidades** muestra que algunos tumores malignos  
  quedan peligrosamente cerca del lÃ­mite de decisiÃ³n (0.5), lo que exige prudencia.
- En el **mapa clÃ­nico (radius vs texture)** los errores no son aleatorios:  
  los Falsos Negativos se concentran en tumores **pequeÃ±os pero estructuralmente irregulares**,  
  una zona donde la IA â€œpierde de vistaâ€ el cÃ¡ncer.

### ğŸ§  ConclusiÃ³n Final  

El modelo es Ãºtil como **herramienta de apoyo**, pero **no puede operar solo**.  
Debe complementarse con reglas de triage como:

> **â€œSi la IA predice Benigno pero el tumor tiene radius o textura en zona de riesgo â†’ revisiÃ³n humana obligatoria.â€**

En este caso, mejorar la sensibilidad hacia los tumores malignos y ajustar el umbral  
no es una recomendaciÃ³n opcional:  
es una **exigencia clÃ­nica** para reducir el riesgo del â€œtumor invisibleâ€.

---

# ğŸ§¬ **Caso 2: EstimaciÃ³n del TamaÃ±o Tumoral con RegresiÃ³n Lineal** ğŸ“ˆ  

### **âš ï¸ SituaciÃ³n Detectada:**

En diagnÃ³stico oncolÃ³gico no basta con clasificar un tumor como **Benigno (1)** o **Maligno (0)**.  
Los mÃ©dicos necesitan estimar **la gravedad continua** del caso, normalmente asociada al  
**tamaÃ±o anatÃ³mico del tumor**, representado por biomarcadores como:

- `mean_radius`  
- `mean_perimeter`  
- `mean_area`

Actualmente, los radiÃ³logos reportan estas medidas manualmente y la escala de severidad  
termina siendo **subjetiva** y dependiente de la experiencia del profesional.

Esto genera tres problemas importantes:

- **Inconsistencia** entre mÃ©dicos al evaluar el mismo tumor.  
- Dificultad para **priorizar pacientes** segÃºn gravedad estimada.  
- No existe un modelo que **prediga automÃ¡ticamente el tamaÃ±o esperado** a partir del resto de caracterÃ­sticas celulares.

El equipo clÃ­nico necesita responder preguntas como:

- Â¿Podemos **predecir el tamaÃ±o tumoral** a partir de variables morfolÃ³gicas mÃ¡s simples?  
- Â¿QuÃ© caracterÃ­sticas del tumor **influyen mÃ¡s** en su crecimiento?  
- Â¿Hasta quÃ© punto un modelo lineal puede **estimar la severidad** sin intervenciÃ³n manual?

### **ğŸ¯ Objetivo de esta secciÃ³n:**

Construir y analizar un modelo de **RegresiÃ³n Lineal** que permita:

- **Estimar el tamaÃ±o tumoral** (`mean_radius`, `mean_perimeter` o `mean_area`)  
  utilizando el resto de biomarcadores como predictores.
- Identificar cuÃ¡les son las **variables que mÃ¡s aportan** al tamaÃ±o del tumor.  
- Detectar si existe **linealidad real** entre estas caracterÃ­sticas o si el tumor crece  
  de forma no lineal y requiere modelos mÃ¡s sofisticados.
- Derivar reglas de apoyo clÃ­nico como:  
  > â€œSi el modelo predice un tamaÃ±o estimado alto, el paciente requiere evaluaciÃ³n prioritariaâ€.

MÃ¡s que buscar una regresiÃ³n perfecta, el propÃ³sito es crear un **estimador interpretable**  
que traduzca las mediciones microscÃ³picas en un indicador cuantitativo de severidad clÃ­nica.

### **CÃ¡lculo Previo: Configurando el Estimador Tumoral** ğŸ”¬ğŸ“

> Este fragmento de preparaciÃ³n deja todo listo para que la RegresiÃ³n Lineal aprenda  
> a estimar el tamaÃ±o del tumor en escala continua:

> 1. **Selecciona** una variable objetivo (`y_size`) como medida del tamaÃ±o anatÃ³mico:  
>    `mean_radius`, `mean_perimeter` o `mean_area`.  
>
> 2. **Define** la matriz de caracterÃ­sticas `X_size` con el resto de biomarcadores celulares.  
>
> 3. **Divide** el dataset en entrenamiento y prueba (`train_test_split`)  
>    para estimar el tamaÃ±o tumoral en casos nuevos.  
>
> 4. **Entrena** una **RegresiÃ³n Lineal**, obteniendo coeficientes Î² que indican  
>    cÃ³mo cada caracterÃ­stica contribuye al crecimiento del tumor.  
>
> 5. **Genera** un panel diagnÃ³stico con:  
>    - PredicciÃ³n vs valor real  
>    - Residuos vs predicciÃ³n  
>    para verificar si la estimaciÃ³n es lineal y estable.

```python hl_lines="6 7 11 12 15" linenums="1"

# 1. Definir objetivo (tamaÃ±o tumoral) y features
y = df["mean radius"]          # TamaÃ±o del tumor
X = df.drop(columns=["mean radius"])

# 2. Train/Test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 3. Entrenar regresiÃ³n lineal
model = LinearRegression()
model.fit(X_train, y_train)

# 4. Predicciones + mÃ©tricas clave
y_pred = model.predict(X_test)
print("RÂ²:", r2_score(y_test, y_pred))
print("RMSE:", mean_squared_error(y_test, y_pred)**0.5)

# 5. GrÃ¡fico esencial: Real vs Predicho
plt.scatter(y_test, y_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()], 'r--')
plt.xlabel("TamaÃ±o real")
plt.ylabel("TamaÃ±o predicho")
plt.title("Real vs Predicho â€“ RegresiÃ³n Lineal")
plt.show()
```

![view4.1.7](../assets/ImgPractica4/img4.2.8.png)

### ğŸ“Š Resultados del Modelo de RegresiÃ³n Lineal (Caso 2)

Tras entrenar la regresiÃ³n lineal para estimar el **tamaÃ±o tumoral (`mean radius`)**, se obtuvieron los siguientes indicadores clave:

---

### ğŸ“ˆ MÃ©tricas de DesempeÃ±o

- **RÂ² (Coeficiente de determinaciÃ³n):**  
  Indica quÃ© proporciÃ³n de la variabilidad del tamaÃ±o tumoral es explicada por el modelo.  
  Un valor alto sugiere una relaciÃ³n lineal fuerte entre los biomarcadores.

- **RMSE (Error CuadrÃ¡tico Medio):**  
  Mide cuÃ¡ntas unidades, en promedio, se desvÃ­a la predicciÃ³n respecto al tamaÃ±o real del tumor.  
  Valores bajos indican una estimaciÃ³n clÃ­nicamente mÃ¡s estable.

---

### ğŸ–¼ï¸ InterpretaciÃ³n del GrÃ¡fico Real vs Predicho

- La mayorÃ­a de los puntos se alinean alrededor de la **diagonal roja**,  
  mostrando que el modelo logra **aproximar adecuadamente** el tamaÃ±o real.
- Se observan algunos desvÃ­os en tumores **muy grandes o muy pequeÃ±os**,  
  seÃ±alando que podrÃ­an requerirse modelos no lineales para mayor precisiÃ³n.

---

### ğŸ§  Dashboard de resultados

El modelo de regresiÃ³n lineal proporciona una **estimaciÃ³n razonablemente buena** del tamaÃ±o tumoral,  
sirviendo como herramienta inicial de apoyo para:

- evaluar la **gravedad continua** del tumor,  
- priorizar pacientes,  
- complementar el diagnÃ³stico preliminar antes de una evaluaciÃ³n mÃ©dica mÃ¡s profunda.

Aunque no es perfecto, ofrece una base cuantitativa sÃ³lida que puede ampliarse con modelos mÃ¡s complejos (Ridge, Lasso o Random Forest).

![view4.1.7](../assets/ImgPractica4/img4.2.9.png)

### âš–ï¸ **Veredicto del Caso 2: La AnatomÃ­a del Crecimiento Tumoral** ğŸ“ˆğŸ§¬

Tras evaluar el modelo de **RegresiÃ³n Lineal** para estimar el tamaÃ±o tumoral (`mean radius`), los resultados son consistentes y reveladores:

- El valor de **RÂ² indica que una proporciÃ³n importante del tamaÃ±o tumoral** puede explicarse a partir de otros biomarcadores celulares.  
- El **RMSE** muestra que el error promedio es razonable, pero sigue habiendo desviaciones relevantes en tumores muy grandes o muy pequeÃ±os.
- En el grÃ¡fico **Real vs Predicho**, la mayorÃ­a de los puntos siguen la diagonal ideal,  
  pero los alejamientos sistemÃ¡ticos evidencian que **la linealidad no captura toda la complejidad clÃ­nica**.
- El grÃ¡fico de **residuos** confirma este patrÃ³n:  
  no hay una aleatoriedad perfecta, lo que sugiere que existen zonas donde el crecimiento tumoral **no sigue una relaciÃ³n lineal**.
- El anÃ¡lisis de **importancia de coeficientes** revela que algunos biomarcadores (como concavidad, perÃ­metro y compactaciÃ³n)  
  tienen una influencia directa y significativa en el tamaÃ±o final del tumor.

---

### ğŸ§  **ConclusiÃ³n Final**

El modelo lineal es una **herramienta Ãºtil para obtener una estimaciÃ³n rÃ¡pida y explicable** del tamaÃ±o tumoral,  
pero no es suficientemente preciso para casos donde el crecimiento sigue patrones no lineales.

Debe utilizarse como **apoyo clÃ­nico preliminar**, nunca como diagnÃ³stico definitivo.

> **â€œSi la predicciÃ³n del modelo difiere mucho del tamaÃ±o observado o cae fuera del rango esperado â†’ se requiere evaluaciÃ³n mÃ©dica y tÃ©cnicas de modelado mÃ¡s avanzadas.â€**