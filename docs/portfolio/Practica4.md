# üìù **TAREA 4: Regresi√≥n Lineal y Log√≠stica - FILL IN THE BLANKS**

<span class="pill">Completado</span>
<span class="pill">#4</span>
<span class="pill">Regresi√≥n Lineal</span>
<span class="pill">Regresi√≥n Log√≠stica</span>
<span class="pill">Machine Learning</span>
<span class="pill">Titanic</span>
<span class="pill">Modelo Base</span>

[**Ver Notebook en Google Colab**](https://colab.research.google.com/drive/114DetBDXPevvD7RS_C5Bg5FB2UjcoZ0I?usp=sharing)  
[**Ver Visualizaciones en Google Drive**](https://drive.google.com/drive/folders/1zLNaoXm94xbjZ3wICLOtBp_4JDL-QcB0?usp=drive_link)  

---

## üèÜ **Resumen Ejecutivo**

En esta tarea, se exploraron dos modelos cl√°sicos de Machine Learning: **Regresi√≥n Lineal** y **Regresi√≥n Log√≠stica**. Ambos modelos fueron aplicados a distintos problemas para comparar su desempe√±o: la predicci√≥n de precios de casas en **Boston** utilizando **Regresi√≥n Lineal** y la clasificaci√≥n de **diagn√≥stico m√©dico de c√°ncer de mama** utilizando **Regresi√≥n Log√≠stica**. El objetivo fue evaluar c√≥mo cada modelo se comporta en **problemas de regresi√≥n** y **clasificaci√≥n** respectivamente.

### **Hallazgos clave:**
- **Regresi√≥n Lineal** se utiliz√≥ para predecir el precio de las casas en el conjunto de datos de **Boston**. Se evalu√≥ con m√©tricas de error como **MAE**, **MSE**, **RMSE**, y **R¬≤**.
- **Regresi√≥n Log√≠stica** se utiliz√≥ para clasificar tumores como **benignos** o **malignos**, utilizando m√©tricas como **precision**, **recall**, **f1-score** y **accuracy**.
- **Regresi√≥n Log√≠stica** mostr√≥ un mejor rendimiento que el modelo base **DummyClassifier**, destacando c√≥mo el **Feature Engineering** y la optimizaci√≥n del modelo pueden mejorar significativamente la precisi√≥n y efectividad.

---

## üéØ **Objetivos de la tarea**

- [x] Aplicar **Regresi√≥n Lineal** para predecir el precio de las casas en el dataset de **Boston**.  
- [x] Implementar **Regresi√≥n Log√≠stica** para la clasificaci√≥n binaria en el dataset de diagn√≥stico m√©dico (c√°ncer de mama).  
- [x] Evaluar ambos modelos con m√©tricas adecuadas como **MAE**, **MSE**, **RMSE**, **accuracy**, **precision**, y **recall**.  
- [x] Comparar el rendimiento de los modelos entrenados contra un **DummyClassifier** como baseline.  

## ‚è±Ô∏è **Actividades y tiempos estimados**

| Actividad                                   | Estimado | Real | Nota |
|---|---:|---:|---|
| Configuraci√≥n inicial en **Google Colab**    | 30 m | **28 m** | Instalaci√≥n y carga de datos. |
| Preprocesamiento y **Feature Engineering**   | 40 m | **42 m** | Manejo de valores faltantes y creaci√≥n de nuevas caracter√≠sticas. |
| Entrenamiento del **DummyClassifier**        | 20 m | **22 m** | Entrenamiento con la estrategia `most_frequent` para baseline. |
| **Entrenamiento de Regresi√≥n Log√≠stica**     | 30 m | **35 m** | Entrenamiento de modelo y evaluaci√≥n. |
| Evaluaci√≥n de modelos y comparaci√≥n          | 30 m | **32 m** | Comparaci√≥n entre modelos y m√©tricas. |
| Reflexi√≥n y discusi√≥n de preguntas           | 15 m | **14 m** | Discusi√≥n sobre hallazgos y rendimiento de los modelos. |

> **Totales** ‚Äî Estimado: **3 h** ¬∑ Real: **3 h 13 m** ¬∑ Œî: **+13 m** (**+6%**).

---

## üí° **Desarrollo: Regresi√≥n Lineal - Predecir Precios de Casas**

### **1. Cargar el Dataset de Boston Housing**
El dataset contiene informaci√≥n sobre viviendas en Boston, incluyendo caracter√≠sticas como **edad de la vivienda**, **n√∫mero de habitaciones** y **distancia a centros de trabajo**.

```python
url = "https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
boston_data = pd.read_csv(url)

# Datos de casas en Boston
print(boston_data.head())
```

### **2. Dividir los datos en entrenamiento y prueba**
- **X (variables independientes):** todas las columnas excepto `medv` (precio).
- **y (variable dependiente):** el precio de las casas.

### **3. Entrenar el modelo de Regresi√≥n Lineal**
Usamos el modelo de **LinearRegression** de **scikit-learn** para predecir el precio de las casas.

```python
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

X = boston_data.drop('medv', axis=1)
y = boston_data['medv']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenamiento de Regresi√≥n Lineal
modelo_regresion = LinearRegression()
modelo_regresion.fit(X_train, y_train)
```

### **4. Evaluaci√≥n del Modelo**
Evaluamos el modelo utilizando varias m√©tricas como **MAE**, **MSE**, **RMSE**, y **R¬≤**:

```python
from sklearn.metrics import mean_squared_error
import numpy as np

# Predicciones
predicciones = modelo_regresion.predict(X_test)

# M√©tricas
mae = mean_absolute_error(y_test, predicciones)
mse = mean_squared_error(y_test, predicciones)
rmse = np.sqrt(mse)
r2 = modelo_regresion.score(X_test, y_test)

print(f"MAE: ${mae:.2f}k")
print(f"MSE: {mse:.2f}")
print(f"RMSE: ${rmse:.2f}k")
print(f"R¬≤: {r2:.3f}")
```

### **5. Interpretaci√≥n**
- **R¬≤** nos dice qu√© porcentaje de la variabilidad en el precio de las casas es explicado por nuestro modelo.
- **MAE** y **RMSE** nos indican cu√°nto se alejan, en promedio, nuestras predicciones del precio real.

---
## üì∏ **Evidencias Visuales**

### Visualizaci√≥n de relaciones en el dataset Titanic

1. **Gr√°fico de Regresi√≥n Lineal - Predicci√≥n de Precios de Casas:**
   ![Gr√°fico de Regresi√≥n Lineal](../../assets/ImgPractica4/imgP3.1.png)
   - **Relaci√≥n entre variables clave**: El n√∫mero de habitaciones (`RM`) y el precio de las casas (`medv`), destacando la tendencia ascendente en los precios conforme aumenta el n√∫mero de habitaciones.

2. **An√°lisis Detallado de la Regresi√≥n Lineal:**
   ![Gr√°fico de Regresi√≥n Detallado](../../assets/ImgPractica4/imgP3.2.png)
   - **Relaci√≥n entre variables clave**: Dispersi√≥n de los datos de precio de casas y n√∫mero de habitaciones, con la l√≠nea de regresi√≥n ajustada para visualizar mejor la correlaci√≥n.


## üè• **Regresi√≥n Log√≠stica - Diagn√≥stico M√©dico**

### **1. Cargar el dataset de c√°ncer de mama**
Utilizamos el dataset **Breast Cancer Wisconsin**, que contiene caracter√≠sticas sobre tumores (benignos o malignos).

```python
from sklearn.datasets import load_breast_cancer

cancer_data = load_breast_cancer()
X_cancer = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)
y_cancer = cancer_data.target
```

### **2. Evaluar el Balance de Clases**
Vemos cu√°ntos tumores son **benignos** y **malignos**:

```python
benignos = (y_cancer == 1).sum()
malignos = (y_cancer == 0).sum()
print(f"Casos benignos: {benignos}")
print(f"Casos malignos: {malignos}")
```

### **3. Entrenar el Modelo de Regresi√≥n Log√≠stica**
Usamos **LogisticRegression** para predecir si un tumor es **benigno** o **maligno**.

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Divisi√≥n de datos
X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(X_cancer, y_cancer, test_size=0.2, random_state=42)

# Entrenamiento de Regresi√≥n Log√≠stica
modelo_clasificacion = LogisticRegression(max_iter=5000, random_state=42)
modelo_clasificacion.fit(X_train_cancer, y_train_cancer)
```

### **4. Evaluar el Modelo**
Calculamos la **exactitud**, **precisi√≥n**, **recall**, y **f1-score**.

```python
# Predicciones
predicciones_cancer = modelo_clasificacion.predict(X_test_cancer)

# M√©tricas
accuracy = accuracy_score(y_test_cancer, predicciones_cancer)
precision = precision_score(y_test_cancer, predicciones_cancer)
recall = recall_score(y_test_cancer, predicciones_cancer)
f1 = f1_score(y_test_cancer, predicciones_cancer)

print(f"Accuracy: {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1-Score: {f1:.3f}")
```

### **5. Interpretaci√≥n**
- **Precision**: De todas las predicciones positivas, ¬øcu√°ntas fueron realmente correctas?
- **Recall**: De todos los casos reales positivos, ¬øcu√°ntos fueron detectados?
- **F1-Score**: Balance entre precisi√≥n y recall, √∫til cuando hay un desbalance de clases.

---

## üì∏ **Evidencias Visuales**

### Visualizaci√≥n de relaciones en el dataset de C√°ncer de Mama

1. **Gr√°fico de Regresi√≥n Log√≠stica - Diagn√≥stico de C√°ncer de Mama:**
   ![Gr√°fico de Regresi√≥n Lineal](../../assets/ImgPractica4/imgP4.1.png)
   - **Relaci√≥n entre variables clave**: El radio medio del tumor (`mean radius`) y el diagn√≥stico (benigno o maligno), destacando la relaci√≥n entre las caracter√≠sticas y la probabilidad de malignidad.

2. **An√°lisis Detallado de la Regresi√≥n Log√≠stica:**
   ![Gr√°fico de Regresi√≥n Detallado](../../assets/ImgPractica4/imgP4.2.png)
   - **Relaci√≥n entre variables clave**: Dispersi√≥n de los datos de suavidad y compactidad del tumor, con la l√≠nea de regresi√≥n ajustada para visualizar mejor la probabilidad de malignidad.



## ‚ùì **Preguntas de Reflexi√≥n**

1. **¬øCu√°l es la diferencia principal entre regresi√≥n lineal y log√≠stica?**
   - **Regresi√≥n Lineal** predice valores num√©ricos continuos (e.g., precio de casas).
   - **Regresi√≥n Log√≠stica** predice categor√≠as (e.g., maligno vs benigno).

2. **¬øPor qu√© dividimos los datos en entrenamiento y prueba?**
   - Para entrenar el modelo en un conjunto de datos y evaluarlo en un conjunto diferente, asegurando que el modelo generalice bien.

3. **¬øQu√© significa una exactitud del 95%?**
   - El modelo predice correctamente el 95% de los casos.

4. **¬øCu√°l es m√°s peligroso: predecir "benigno" cuando es "maligno", o al rev√©s?**
   - Es m√°s peligroso predecir "benigno" cuando en realidad es "maligno", ya que podr√≠a no tratar a un paciente con un tumor maligno a tiempo.

---

## Parte 3: Actividad Final - Compara los Dos Modelos

Puedes acceder al archivo PDF de la actividad final a continuaci√≥n:

<a href="assets/VAEZ ALVAREZ LUIS- CV[1].pdf" target="_blank" style="display:inline-block; padding:10px 20px; margin-top:10px; background-color:#4CAF50; color:white; text-align:center; text-decoration:none; border-radius:5px; font-size:16px;">Descargar Actividad Final - Compara los Dos Modelos</a>


## üßë‚Äçüíª **Reproducibilidad**

```bash
pip install -q scikit-learn matplotlib seaborn
```

```python
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Cargar datos
data = pd.read_csv('titanic.csv')

# Preparar datos
X = data[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]
y = data['Survived']
X = pd.get_dummies(X, drop_first=True)

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Regresi√≥n Log√≠stica
lr = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)
lr.fit(X_train, y_train)
predictions = lr.predict(X_test)

# Evaluaci√≥n
print("Accuracy:", accuracy_score(y_test, predictions))
```

---

## üí° **Conclusi√≥n**

El **Feature Engineering** y el entrenamiento de modelos como **Regresi√≥n Log√≠stica** y **Lineal** nos permitieron obtener **modelos m√°s precisos y efectivos**. Continuaremos ajustando estos modelos y aplicando nuevas t√©cnicas para mejorar la predicci√≥n en problemas de regresi√≥n y clasificaci√≥n.

---
# üöÄ **Explora el Notebook Interactivo en Google Colab** üéì

Haz clic en el siguiente **bot√≥n** para acceder al **notebook** interactivo y realizar el an√°lisis directamente en Google Colab:

[![Ver Notebook en Google Colab](https://img.shields.io/badge/Accede%20al%20Notebook%20en%20Google%20Colab-brightgreen?style=for-the-badge&logo=googlecolab)](https://colab.research.google.com/drive/114DetBDXPevvD7RS_C5Bg5FB2UjcoZ0I?usp=sharing)

> **¬°Haz clic para empezar a trabajar directamente en el c√≥digo y explorar las visualizaciones en tiempo real!**

---
