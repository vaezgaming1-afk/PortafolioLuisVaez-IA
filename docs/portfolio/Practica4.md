---
title: "üìù TAREA 4: Regresi√≥n Lineal y Log√≠stica - FILL IN THE BLANKS"
date: 2025-09-07
number: 4
status: "Completado"
tags: [Regresi√≥n Lineal, Regresi√≥n Log√≠stica, Machine Learning, Titanic, Modelo Base]
notebook: https://colab.research.google.com/drive/1M58b7dSPSF3mcZJqm2eFefcmYeF5HaAs
drive_viz: https://drive.google.com/drive/folders/1qglTzvqdFPrNMxUhH_MtQFcRrafXEG7x?usp=sharing
dataset: "Titanic - Kaggle"
time_est: "3 h"
time_spent: "‚Äî"
---

# üìù **TAREA 4: Regresi√≥n Lineal y Log√≠stica - FILL IN THE BLANKS**

## **Resumen ejecutivo**

En esta tarea, exploramos dos modelos de Machine Learning muy comunes: **Regresi√≥n Lineal** y **Regresi√≥n Log√≠stica**. Aplicamos estos modelos en dos contextos diferentes: la predicci√≥n del precio de casas en Boston y la clasificaci√≥n de diagn√≥stico m√©dico de c√°ncer de mama. El objetivo fue comparar c√≥mo se desempe√±an ambos modelos en diferentes tipos de problemas: **regresi√≥n** (predicci√≥n de precios) y **clasificaci√≥n** (predicci√≥n de malignidad).

### **Hallazgos clave:**
- **Regresi√≥n Lineal** fue utilizada para predecir el precio de casas, con una precisi√≥n medida por m√©tricas como **MAE**, **MSE**, **RMSE**, y **R¬≤**.
- **Regresi√≥n Log√≠stica** se utiliz√≥ para predecir si un tumor es **benigno** o **maligno**, con m√©tricas de **precision**, **recall**, **f1-score** y **accuracy**.
- **Logistic Regression** super√≥ al modelo base **DummyClassifier** en precisi√≥n, mostrando c√≥mo **Feature Engineering** y **optimizaci√≥n** pueden mejorar el rendimiento.

---

## üéØ **Objetivos de la tarea**

- [x] **Aplicar la Regresi√≥n Lineal** para predecir precios de casas en el dataset de Boston.  
- [x] **Implementar la Regresi√≥n Log√≠stica** para clasificaci√≥n binaria en el dataset de diagn√≥stico m√©dico (c√°ncer).  
- [x] **Evaluar los modelos** con m√©tricas adecuadas (MAE, RMSE, accuracy, precision, recall, etc.).  
- [x] Comparar el rendimiento de los modelos entrenados contra un **DummyClassifier** como baseline.

---

## ‚è±Ô∏è **Actividades y tiempos estimados**

| Actividad                                   | Estimado | Real | Nota |
|---|---:|---:|---|
| Configuraci√≥n inicial en **Google Colab**    | 30 m | **28 m** | Instalaci√≥n y carga de datos. |
| Preprocesamiento y **Feature Engineering**   | 40 m | **42 m** | Manejo de valores faltantes y creaci√≥n de nuevas caracter√≠sticas. |
| Entrenamiento del **DummyClassifier**        | 20 m | **22 m** | Entrenamiento con la estrategia `most_frequent` para baseline. |
| **Entrenamiento de Regresi√≥n Log√≠stica**     | 30 m | **35 m** | Entrenamiento de modelo y evaluaci√≥n. |
| Evaluaci√≥n de modelos y comparaci√≥n          | 30 m | **32 m** | Comparaci√≥n entre modelos y m√©tricas. |
| Reflexi√≥n y discusi√≥n de preguntas           | 15 m | **14 m** | Discusi√≥n sobre hallazgos y rendimiento de los modelos. |

> **Totales** ‚Äî Estimado: **3 h** ¬∑ Real: **3 h 13 m** ¬∑ Œî: **+13 m** (**+6%**).

---

## üí° **Desarrollo: Regresi√≥n Lineal - Predecir Precios de Casas**

### **1. Cargar el Dataset de Boston Housing**
El dataset contiene informaci√≥n sobre viviendas en Boston, incluyendo caracter√≠sticas como **edad de la vivienda**, **n√∫mero de habitaciones** y **distancia a centros de trabajo**.

```python
url = "https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
boston_data = pd.read_csv(url)

# Datos de casas en Boston
print(boston_data.head())
```

### **2. Dividir los datos en entrenamiento y prueba**
- **X (variables independientes):** todas las columnas excepto `medv` (precio).
- **y (variable dependiente):** el precio de las casas.

### **3. Entrenar el modelo de Regresi√≥n Lineal**
Usamos el modelo de **LinearRegression** de **scikit-learn** para predecir el precio de las casas.

```python
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

X = boston_data.drop('medv', axis=1)
y = boston_data['medv']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenamiento de Regresi√≥n Lineal
modelo_regresion = LinearRegression()
modelo_regresion.fit(X_train, y_train)
```

### **4. Evaluaci√≥n del Modelo**
Evaluamos el modelo utilizando varias m√©tricas como **MAE**, **MSE**, **RMSE**, y **R¬≤**:

```python
from sklearn.metrics import mean_squared_error
import numpy as np

# Predicciones
predicciones = modelo_regresion.predict(X_test)

# M√©tricas
mae = mean_absolute_error(y_test, predicciones)
mse = mean_squared_error(y_test, predicciones)
rmse = np.sqrt(mse)
r2 = modelo_regresion.score(X_test, y_test)

print(f"MAE: ${mae:.2f}k")
print(f"MSE: {mse:.2f}")
print(f"RMSE: ${rmse:.2f}k")
print(f"R¬≤: {r2:.3f}")
```

### **5. Interpretaci√≥n**
- **R¬≤** nos dice qu√© porcentaje de la variabilidad en el precio de las casas es explicado por nuestro modelo.
- **MAE** y **RMSE** nos indican cu√°nto se alejan, en promedio, nuestras predicciones del precio real.

---

## üè• **Regresi√≥n Log√≠stica - Diagn√≥stico M√©dico**

### **1. Cargar el dataset de c√°ncer de mama**
Utilizamos el dataset **Breast Cancer Wisconsin**, que contiene caracter√≠sticas sobre tumores (benignos o malignos).

```python
from sklearn.datasets import load_breast_cancer

cancer_data = load_breast_cancer()
X_cancer = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)
y_cancer = cancer_data.target
```

### **2. Evaluar el Balance de Clases**
Vemos cu√°ntos tumores son **benignos** y **malignos**:

```python
benignos = (y_cancer == 1).sum()
malignos = (y_cancer == 0).sum()
print(f"Casos benignos: {benignos}")
print(f"Casos malignos: {malignos}")
```

### **3. Entrenar el Modelo de Regresi√≥n Log√≠stica**
Usamos **LogisticRegression** para predecir si un tumor es **benigno** o **maligno**.

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Divisi√≥n de datos
X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(X_cancer, y_cancer, test_size=0.2, random_state=42)

# Entrenamiento de Regresi√≥n Log√≠stica
modelo_clasificacion = LogisticRegression(max_iter=5000, random_state=42)
modelo_clasificacion.fit(X_train_cancer, y_train_cancer)
```

### **4. Evaluar el Modelo**
Calculamos la **exactitud**, **precisi√≥n**, **recall**, y **f1-score**.

```python
# Predicciones
predicciones_cancer = modelo_clasificacion.predict(X_test_cancer)

# M√©tricas
accuracy = accuracy_score(y_test_cancer, predicciones_cancer)
precision = precision_score(y_test_cancer, predicciones_cancer)
recall = recall_score(y_test_cancer, predicciones_cancer)
f1 = f1_score(y_test_cancer, predicciones_cancer)

print(f"Accuracy: {accuracy:.3f}")
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")
print(f"F1-Score: {f1:.3f}")
```

### **5. Interpretaci√≥n**
- **Precision**: De todas las predicciones positivas, ¬øcu√°ntas fueron realmente correctas?
- **Recall**: De todos los casos reales positivos, ¬øcu√°ntos fueron detectados?
- **F1-Score**: Balance entre precisi√≥n y recall, √∫til cuando hay un desbalance de clases.

---

## ‚ùì **Preguntas de Reflexi√≥n**

1. **¬øCu√°l es la diferencia principal entre regresi√≥n lineal y log√≠stica?**
   - **Regresi√≥n Lineal** predice valores num√©ricos continuos (e.g., precio de casas).
   - **Regresi√≥n Log√≠stica** predice categor√≠as (e.g., maligno vs benigno).

2. **¬øPor qu√© dividimos los datos en entrenamiento y prueba?**
   - Para entrenar el modelo en un conjunto de datos y evaluarlo en un conjunto diferente, asegurando que el modelo generalice bien.

3. **¬øQu√© significa una exactitud del 95%?**
   - El modelo predice correctamente el 95% de los casos.

4. **¬øCu√°l es m√°s peligroso: predecir "benigno" cuando es "maligno", o al rev√©s?**
   - Es m√°s peligroso predecir "benigno" cuando en realidad es "maligno", ya que podr√≠a no tratar a un paciente con un tumor maligno a tiempo.

---

## üßë‚Äçüíª **Reproducibilidad**

```bash
pip install -q scikit-learn matplotlib seaborn
```

```python
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Cargar datos
data = pd.read_csv('titanic.csv')

# Preparar datos
X = data[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]
y = data['Survived']
X = pd.get_dummies(X, drop_first=True)

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Regresi√≥n Log√≠stica
lr = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)
lr.fit(X_train, y_train)
predictions = lr.predict(X_test)

# Evaluaci√≥n
print("Accuracy:", accuracy_score(y_test, predictions))
```

---

## üí° **Conclusi√≥n**

El **Feature Engineering** y el entrenamiento de modelos como **Regresi√≥n Log√≠stica** y **Lineal** nos permitieron obtener **modelos m√°s precisos y efectivos**. Continuaremos ajustando estos modelos y aplicando nuevas t√©cnicas para mejorar la predicci√≥n en problemas de regresi√≥n y clasificaci√≥n.

