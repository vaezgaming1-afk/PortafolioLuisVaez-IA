<h1 align="center"> PredicciÃ³n del Rendimiento Estudiantil: De Modelos Baseline a Pipelines Profesionales en Scikit-learn ğŸ“ğŸš€</h1>

![StudentPerformanceBanner](../assets/ImgPractica5/img5.1.1.png)

<p align="center">
  <em>Analizando factores acadÃ©micos, sociales y demogrÃ¡ficos para entender el desempeÃ±o estudiantil y construir modelos predictivos robustos.</em>
</p>

ğŸ·ï¸ **Etiquetas RÃ¡pidas**  
`#StudentPerformance` `#MLPipelines` `#RegresiÃ³n` `#ClasificaciÃ³n` `#UCI` `#FeatureEngineering`

---

## ğŸš€ Accesos Directos Importantes

<div align="center">

<a href="https://colab.research.google.com/drive/XXXXX_TU_ENLACE_XXXXX">
  <img src="https://img.shields.io/badge/Abrir%20Notebook-Google%20Colab-brightgreen?style=for-the-badge&logo=googlecolab&logoColor=white" alt="Abrir Notebook en Colab" />
</a>

&nbsp;

<a href="https://drive.google.com/drive/folders/XXXXX_TU_DRIVE_XXXXX">
  <img src="https://img.shields.io/badge/Visualizaciones-Google%20Drive-blue?style=for-the-badge&logo=google-drive&logoColor=white" alt="Ver visualizaciones en Drive" />
</a>

</div>

---

# ğŸ§  **Resumen Ejecutivo**

ğŸ¯ **Objetivo General:**  
Explorar el dataset clÃ¡sico **Student Performance** (UCI) para comprender quÃ© factores influyen en la nota final (**G3**) y construir modelos predictivos mediante **pipelines**, ingenierÃ­a de caracterÃ­sticas y validaciÃ³n cruzada estratificada.

ğŸ“Œ **Hallazgos clave preliminares:**

- El dataset incluye **649 estudiantes** y mÃ¡s de **30 variables** que abarcan entorno familiar, hÃ¡bitos de estudio y desempeÃ±o previo.
- **G3** puede usarse tanto para **regresiÃ³n** como para **clasificaciÃ³n** mediante umbrales (por ejemplo, *alto rendimiento = G3 â‰¥ 10*).
- La abundancia de variables categÃ³ricas convierte este dataset en un escenario ideal para:
  - `ColumnTransformer`
  - `OneHotEncoder`
  - `Pipeline`
  - `StandardScaler`
  - `StratifiedKFold`  
- Los primeros modelos muestran mejoras sustanciales al agregar:
  - mejor codificaciÃ³n categÃ³rica,  
  - estandarizaciÃ³n adecuada,  
  - modelos mÃ¡s robustos como **Logistic Regression**, **RandomForest**, **RidgeClassifier** y otros.

ğŸ“ˆ **Resultado preliminar:**  
Los pipelines bien estructurados superan ampliamente los modelos baseline, ofreciendo un flujo reproducible y limpio para comparar algoritmos de forma justa.

---

# ğŸ¯ **Objetivos EspecÃ­ficos**

| Objetivo                                                                       | Estado |
|--------------------------------------------------------------------------------|--------|
| Analizar la estructura del dataset y variables principales                     | âœ…      |
| Construir variable objetivo binaria **(high_performance)**                     | âœ…      |
| Separar variables categÃ³ricas y numÃ©ricas para un **ColumnTransformer**        | âœ…      |
| DiseÃ±ar un pipeline generalizable con **OneHotEncoder + StandardScaler**        | âœ…      |
| Comparar modelos mediante **StratifiedKFold + cross_val_score**                | â³      |
| Evaluar rendimiento de LogisticReg, RandomForest, RidgeClassifier, etc.        | â³      |

---

# ğŸ“… **Actividades y Tiempos**

| Actividad                                                 | Estimado | Real  | Nota                                                    |
|-----------------------------------------------------------|----------|-------|---------------------------------------------------------|
| Carga y exploraciÃ³n inicial del dataset                   | 20 m     | 18 m  | RevisiÃ³n de estructura, nulos, tipos de dato            |
| CreaciÃ³n de variable binaria **high_performance**         | 10 m     | 8 m   | Umbral en G3                                            |
| PreparaciÃ³n del pipeline (cat vs num)                     | 25 m     | 28 m  | ConfiguraciÃ³n de ColumnTransformer                       |
| ImplementaciÃ³n de clasificaciÃ³n con varios modelos        | 40 m     | â€”     | En ejecuciÃ³n                                            |
| ValidaciÃ³n cruzada, mÃ©tricas y comparaciÃ³n de resultados  | 30 m     | â€”     | A completar                                              |

ğŸ•’ **Total estimado:** 2 h 05 m Â· **Total real (actual):** 54 m

---

# ğŸ› ï¸ **Feature Engineering Aplicado**

| TÃ©cnica                  | DescripciÃ³n                                                                 |
|--------------------------|------------------------------------------------------------------------------|
| **CodificaciÃ³n categÃ³rica** | OneHotEncoder sobre todas las variables nominales                         |
| **EstandarizaciÃ³n**      | StandardScaler sobre variables numÃ©ricas                                    |
| **Nueva variable**        | `high_performance = (G3 >= 10).astype(int)`                                 |
| **Transformaciones previas** | Limpieza de tipos, conversiÃ³n automÃ¡tica de categorÃ­as                     |

---

# âš™ï¸ **Modelos Considerados**

#### ğŸ”¹ **RegresiÃ³n (opcional)**
- `LinearRegression`
- `Ridge`
- `RandomForestRegressor`

#### ğŸ”¸ **ClasificaciÃ³n**
- `LogisticRegression`  
- `RandomForestClassifier`  
- `RidgeClassifier`  
- `KNeighborsClassifier`  
- `GradientBoostingClassifier`

Cada uno evaluado bajo el mismo pipeline, evitando fugas de informaciÃ³n y garantizando comparabilidad.

---

