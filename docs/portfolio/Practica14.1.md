<h1 align="center"> Asistente Inteligente para DocumentaciÃ³n LangChain: Mini-RAG con OpenAI âš™ï¸ğŸ“š</h1>


![CustomerPersonaBanr](../assets/ImgPractica14/img14.2.png)


<p align="center">
  <em>ConstrucciÃ³n de un sistema de recuperaciÃ³n aumentada (RAG) basado en la documentaciÃ³n oficial de LangChain. Un caso prÃ¡ctico que integra embeddings, vector stores, text splitting y cadenas de consulta con ChatOpenAI.</em>
</p>

---

ğŸ·ï¸ **Etiquetas RÃ¡pidas**  
#RAG #LangChain #OpenAI #VectorStores #FAISS #Embeddings #LLMApps #DocumentationQA #AIEngineering

---

## ğŸ§  Resumen Ejecutivo

Este proyecto implementa un **asistente conversacional especializado en la documentaciÃ³n de LangChain**, utilizando un pipeline completo de **RAG (Retrieval-Augmented Generation)**.  
Para lograrlo, se usa el dataset preprocesado **mayur456/langchain_docs**, el cual contiene fragmentos limpios y listos para indexaciÃ³n.

El sistema permite:

- Consultas tÃ©cnicas tipo FAQ,  
- ExplicaciÃ³n de conceptos clave de LangChain,  
- GeneraciÃ³n de resÃºmenes contextuales,  
- ExtracciÃ³n de informaciÃ³n relevante (â€œstructured extractionâ€),  
- ComparaciÃ³n entre respuestas con y sin recuperaciÃ³n de contexto.

Es una prÃ¡ctica ideal dentro del mÃ³dulo UT4-14 porque integra:

- **ChatPromptTemplate**  
- **ChatOpenAI**  
- **Text Splitters**  
- **Vector stores (FAISS)**  
- **Embeddings**  
- **Cadenas de recuperaciÃ³n (retrieval chains)**  

El resultado final es un mini-asistente completamente funcional, reproducible en Google Colab y pensado para portafolios de AI/LLM Engineering.

---

## ğŸ¯ Objetivos del Proyecto

1. **Cargar y estandarizar el dataset** de documentaciÃ³n tÃ©cnica (â€œlangchain_docsâ€).  
2. **Preprocesar contenido** mediante conversiÃ³n a documentos y text splitting recursivo.  
3. **Generar embeddings** optimizados con OpenAI.  
4. **Construir un vector store FAISS** para bÃºsquedas semÃ¡nticas rÃ¡pidas.  
5. **Configurar un retriever** capaz de devolver contexto relevante.  
6. **Implementar una cadena RAG completa**:  
   - recuperaciÃ³n de contexto,  
   - ensamblado con prompt estructurado,  
   - respuesta final condicionada al contexto.  
7. **Demostrar contraste** entre respuestas:  
   - modelo *solo* (sin contexto),  
   - modelo con RAG (context-aware).  

---

## ğŸ“¦ Dataset: *mayur456/langchain_docs*

El dataset contiene:

- **text** â†’ fragmentos de la documentaciÃ³n oficial de LangChain  
- **source** â†’ URL o archivo de origen  
- **metadata opcional** â†’ estructura jerÃ¡rquica  

CaracterÃ­sticas:

- Limpieza previa de HTML y markdown.  
- Dividido en filas relativamente largas aptas para text splitting.  
- Pensado para tareas de QA, resumen, extracciÃ³n y RAG.

Este dataset permite construir un asistente tÃ©cnico coherente:  
**â€œLangChain explicado por LangChain mismoâ€**.

---
