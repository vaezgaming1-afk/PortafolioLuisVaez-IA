---
title: "ğŸ“ Tarea 5: ValidaciÃ³n y SelecciÃ³n de Modelos - Fill in the Blanks"
date: 2025-09-07
number: 5
status: "Completado"
tags: [Machine Learning, ValidaciÃ³n de Modelos, SelecciÃ³n de Modelos, Cross-validation]
notebook: https://colab.research.google.com/drive/11HF94BcKLXSQA5HYoROzCNkrZ5YMThvc?usp=sharing
drive_viz: https://drive.google.com/drive/folders/1qglTzvqdFPrNMxUhH_MtQFcRrafXEG7x?usp=sharing
dataset: "Student Dropout and Academic Success"
time_est: "4 h"
time_spent: "â€”"

---

# ğŸ“ **TAREA 5: ValidaciÃ³n y SelecciÃ³n de Modelos**

[![ğŸ“˜ Abrir Notebook en Google Colab](https://img.shields.io/badge/Abrir%20Notebook-Google%20Colab-brightgreen?style=for-the-badge&logo=googlecolab&logoColor=white)](https://colab.research.google.com/drive/11HF94BcKLXSQA5HYoROzCNkrZ5YMThvc?usp=sharing)  
[![ğŸ“Š Ver Visualizaciones en Drive](https://img.shields.io/badge/Visualizaciones-Google%20Drive-blue?style=for-the-badge&logo=google-drive&logoColor=white)](https://drive.google.com/drive/folders/1u5slVR1ntJ0QzvihEHKp0MX1on18Jo3y?usp=drive_link)

> âœ… *Haz clic en los botones para abrir el notebook y explorar las visualizaciones interactivas.*

## ğŸ¯ **Objetivos BÃ¡sicos**


En esta tarea, aprenderemos cÃ³mo **validar** y **seleccionar modelos** de manera adecuada, utilizando **validaciÃ³n cruzada** y comparando diferentes algoritmos para decidir cuÃ¡l es el mejor para predecir el **abandono estudiantil** y el **Ã©xito acadÃ©mico**.

- Prevenir **data leakage** usando pipelines.
- Implementar **validaciÃ³n cruzada** robusta.
- Comparar mÃºltiples modelos de forma sistemÃ¡tica.
- Interpretar mÃ©tricas de **estabilidad** y **selecciÃ³n de modelos**.

## ğŸ“‹ **Lo que necesitas saber ANTES de empezar:**

Antes de comenzar, es importante que entiendas los siguientes conceptos:

- **Train/test split**: cÃ³mo dividir un conjunto de datos en entrenamiento y prueba.
- Diferencia entre **regresiÃ³n** y **clasificaciÃ³n**.
- Uso bÃ¡sico de **sklearn** y **pandas** para cargar y manejar datos.

---


## ğŸ“ **Dataset: PredicciÃ³n de Ã‰xito Estudiantil**

### **Contexto del negocio:**

**Problema:** Predecir el **abandono estudiantil** y el **Ã©xito acadÃ©mico** en la educaciÃ³n superior.

**Objetivo:** Identificar estudiantes en riesgo para implementar **estrategias de apoyo**.

**Valor:** Reducir las tasas de abandono y mejorar la **retenciÃ³n estudiantil**.

### **CaracterÃ­sticas del Dataset:**

- **36 caracterÃ­sticas** relacionadas con las variables **demogrÃ¡ficas**, **acadÃ©micas** y **socioeconÃ³micas** de los estudiantes.
- **Variable objetivo:** PredicciÃ³n de si un estudiante **abandonÃ³** o **se graduÃ³**.

### **Explorando el Dataset:**

1ï¸âƒ£ **Â¿CuÃ¡ntas muestras y caracterÃ­sticas tiene el dataset?**

- **Muestras:** 4424 estudiantes.
- **CaracterÃ­sticas:** 36 variables (demogrÃ¡ficas, acadÃ©micas y socioeconÃ³micas).

2ï¸âƒ£ **Â¿QuÃ© tipos de variables incluye?**

- **DemogrÃ¡ficas:** Estado civil, nacionalidad, gÃ©nero, edad al momento de la inscripciÃ³n, ocupaciÃ³n de los padres.
- **AcadÃ©micas:** Calificaciones previas, unidades curriculares aprobadas, desempeÃ±o acadÃ©mico en semestres anteriores.
- **SocioeconÃ³micas:** Tasa de desempleo, inflaciÃ³n, PIB.

3ï¸âƒ£ **Â¿Las clases estÃ¡n balanceadas o desbalanceadas?**

- El dataset tiene un **desbalance** en las clases: mÃ¡s estudiantes graduados que los que abandonaron.

4ï¸âƒ£ **Â¿QuÃ© significan las 2 categorÃ­as objetivo?**

- **Dropout**: Estudiantes que han abandonado la educaciÃ³n superior.
- **Graduate**: Estudiantes que han completado sus estudios con Ã©xito.

---

## ğŸ”§ **Paso 1: Setup Inicial**

Antes de comenzar con la validaciÃ³n cruzada, cargamos las bibliotecas necesarias y los datos:

```python
!pip install ucimlrepo
```

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from ucimlrepo import fetch_ucirepo
from sklearn.metrics import accuracy_score, classification_report

print("âœ… Setup completo!")
```

---

## ğŸ“ **Paso 2: Cargar y Explorar Datos**

Cargamos el **dataset de estudiantes** y comenzamos a explorar las caracterÃ­sticas y clases para entender mejor los datos.

```python
# Cargar dataset de estudiantes desde UCI
student_data = fetch_ucirepo(id=697)

# Preparar datos
X = student_data.data.features
y = student_data.data.targets

print("Dataset: Student Dropout and Academic Success")
print(f"Estudiantes: {X.shape[0]}, CaracterÃ­sticas: {X.shape[1]}")
print(f"Objetivo: Predecir {len(y.columns)} variable(s)")

# Explorar variable objetivo
target_col = y.columns[0]  # Primera columna objetivo
y_series = y[target_col]
print(f"\nVariable objetivo: {target_col}")

# Mapear valores para mejor interpretaciÃ³n
target_mapping = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}
y_mapped = y_series.map(target_mapping)

# DistribuciÃ³n de clases
print("\nDistribuciÃ³n de resultados acadÃ©micos:")
value_counts = y_mapped.value_counts()
for outcome, count in value_counts.items():
    percentage = (count / len(y_mapped)) * 100
    print(f"  {outcome}: {count} estudiantes ({percentage:.1f}%)")

# Ver algunas caracterÃ­sticas
print(f"\nPrimeras caracterÃ­sticas:")
print(X.columns.tolist()[:10], "...")

# EstadÃ­sticas bÃ¡sicas
print(f"\nAge at enrollment:")
if 'Age at enrollment' in X.columns:
    age_col = X['Age at enrollment']
    print(f"  Promedio: {age_col.mean():.1f} aÃ±os")
    print(f"  Rango: {age_col.min():.0f}-{age_col.max():.0f} aÃ±os")
```
Salida:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dataset: Student Dropout and Academic Success â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Estudiantes: 4424                            â”‚
â”‚ CaracterÃ­sticas: 36                           â”‚
â”‚ Objetivo: Predecir 1 variable(s)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Variable objetivo: Target                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DistribuciÃ³n de resultados acadÃ©micos:       â”‚
â”‚   2: 2209 estudiantes (49.9%)                â”‚
â”‚   0: 1421 estudiantes (32.1%)                â”‚
â”‚   1: 794 estudiantes (17.9%)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Primeras caracterÃ­sticas:                     â”‚
â”‚   ['Marital Status', 'Application mode',     â”‚
â”‚    'Application order', 'Course',            â”‚
â”‚    'Daytime/evening attendance',             â”‚
â”‚    'Previous qualification',                 â”‚
â”‚    'Previous qualification (grade)',         â”‚
â”‚    'Nacionality',                             â”‚
â”‚    "Mother's qualification",                 â”‚
â”‚    "Father's qualification"]                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Age at enrollment:                            â”‚
â”‚   Promedio: 23.3 aÃ±os                         â”‚
â”‚   Rango: 17-70 aÃ±os                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
### **DistribuciÃ³n de las clases**

DistribuciÃ³n de la variable objetivo:

- **Graduate:** 2209 estudiantes (49.9%)
- **Dropout:** 1421 estudiantes (32.1%)
- **Enrolled:** 794 estudiantes (17.9%)

---

## ğŸ”¬ **Parte 1: ValidaciÃ³n Cruzada - ValidaciÃ³n Robusta**

Para evaluar el rendimiento del modelo y evitar **overfitting**, implementamos la validaciÃ³n cruzada. Usaremos **KFold** y **StratifiedKFold**.

### **ConfiguraciÃ³n del Pipeline y ValidaciÃ³n Cruzada**

```python
# Preparar datos para validaciÃ³n
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
reverse_mapping = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}

# Si y_series contiene strings, convertir a nÃºmeros
y_target = y_series.map(reverse_mapping)

X_features = X  # CaracterÃ­sticas del dataset

# Crear pipeline con escalado de caracterÃ­sticas y clasificaciÃ³n
pipeline_robust = Pipeline([
    ('scaler', StandardScaler()),  # Escalado de caracterÃ­sticas
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))  # Clasificador de regresiÃ³n logÃ­stica
])

# Crear KFold bÃ¡sico
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
scores_kfold = cross_val_score(pipeline_robust, X_features, y_target, cv=kfold, scoring='accuracy')

print(f"\nKFOLD RESULTS:")
print(f"   Scores individuales: {scores_kfold}")
print(f"   Media: {scores_kfold.mean():.4f}")
print(f"   DesviaciÃ³n estÃ¡ndar: {scores_kfold.std():.4f}")
print(f"   Resultado: {scores_kfold.mean():.4f} Â± {scores_kfold.std():.4f}")
```

### ğŸ“Š DistribuciÃ³n de Scores - ValidaciÃ³n Cruzada

![DistribuciÃ³n de Scores](../assets/ImgPractica5/imgP5.1.png)

- Este grÃ¡fico muestra la **distribuciÃ³n de la exactitud (accuracy)** obtenida mediante **validaciÃ³n cruzada** con dos mÃ©todos:
  - **KFold**: DivisiÃ³n simple en 5 particiones, sin mantener proporciÃ³n de clases.
  - **StratifiedKFold**: DivisiÃ³n en 5 particiones manteniendo la proporciÃ³n de clases, ideal para datasets desbalanceados.
- Se observa la **mediana**, los **cuartiles** y la **variabilidad** de los scores de cada mÃ©todo.
- Permite comparar la **estabilidad** de los modelos y decidir quÃ© tÃ©cnica de validaciÃ³n cruzada usar.

# ğŸ”¬ VALIDACIÃ“N CRUZADA: Â¿QuÃ© tan estable es nuestro modelo?


```python
# ValidaciÃ³n Cruzada: Â¿QuÃ© tan estable es nuestro modelo?

from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold
import numpy as np
import matplotlib.pyplot as plt

# Definir el modelo (por ejemplo, un clasificador)
model = ...

# KFold
kfold = KFold(n_splits=5, random_state=42, shuffle=True)
scores_kfold = cross_val_score(model, X, y, cv=kfold)
print(f"KFOLD RESULTS: Scores individuales: {scores_kfold}")
print(f"Media: {np.mean(scores_kfold):.4f}")
print(f"DesviaciÃ³n estÃ¡ndar: {np.std(scores_kfold):.4f}")
print(f"Resultado: {np.mean(scores_kfold):.4f} Â± {np.std(scores_kfold):.4f}")

# StratifiedKFold
stratified_kfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)
scores_stratified = cross_val_score(model, X, y, cv=stratified_kfold)
print(f"STRATIFIED KFOLD RESULTS: Scores individuales: {scores_stratified}")
print(f"Media: {np.mean(scores_stratified):.4f}")
print(f"DesviaciÃ³n estÃ¡ndar: {np.std(scores_stratified):.4f}")
print(f"Resultado: {np.mean(scores_stratified):.4f} Â± {np.std(scores_stratified):.4f}")

# ComparaciÃ³n de estabilidad
print("\nCOMPARACIÃ“N DE ESTABILIDAD:")
if np.std(scores_stratified) < np.std(scores_kfold):
    print("StratifiedKFold es MÃS ESTABLE (menor variabilidad)")
else:
    print("KFold es MÃS ESTABLE (menor variabilidad)")

# RecomendaciÃ³n
print("RecomendaciÃ³n: Usar StratifiedKFold para este dataset")

# Graficar los resultados
plt.boxplot([scores_kfold, scores_stratified], tick_labels=['KFold', 'StratifiedKFold'])
plt.title('ComparaciÃ³n de Estabilidad entre KFold y StratifiedKFold')
plt.ylabel('PuntuaciÃ³n')
plt.show()
```


## ğŸ”¬ **Parte 2: ComparaciÃ³n de Modelos**

Evaluamos el rendimiento de varios modelos de clasificaciÃ³n para ver cuÃ¡l tiene un mejor desempeÃ±o en el problema de **abandono estudiantil**:

```python
# Importar las librerÃ­as necesarias
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt

# ğŸ† TORNEO: Â¿CuÃ¡l modelo funciona mejor para diagnÃ³stico mÃ©dico?
print("ğŸ† TORNEO: Â¿CuÃ¡l modelo funciona mejor para diagnÃ³stico mÃ©dico?")

# 1. Definir candidatos (diferentes algoritmos)
models = {
    'Logistic Regression': Pipeline([  # 1. RegresiÃ³n logÃ­stica
        ('scaler', StandardScaler()),  # Escalado de caracterÃ­sticas
        ('classifier', LogisticRegression(max_iter=1000, random_state=42))  # Clasificador de regresiÃ³n logÃ­stica
    ]),

    # 2. Ridge Classifier (regresiÃ³n logÃ­stica con regularizaciÃ³n L2)
    'Ridge Classifier': Pipeline([
        ('scaler', StandardScaler()),  # Escalado de caracterÃ­sticas
        ('classifier', RidgeClassifier(alpha=1.0, random_state=42))  # Clasificador Ridge
    ]),

    # 3. Random Forest (ensemble, no necesita escalado)
    'Random Forest': Pipeline([
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # Clasificador Random Forest
    ])
}

print(f"Modelos en competencia: {list(models.keys())}")

# 4. Evaluar cada modelo con validaciÃ³n cruzada
print(f"\nEVALUANDO MODELOS CON 5-FOLD CV...")

results = {}
for name, model in models.items():
    print(f"   Evaluando {name}...")

    # Usar StratifiedKFold para mantener balance de clases
    scores = cross_val_score(
        model, X_features, y_target,
        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
        scoring='accuracy'
    )

    results[name] = scores

    print(f"   {name}: {scores.mean():.4f} Â± {scores.std():.4f}")
    print(f"      Scores: {[f'{s:.3f}' for s in scores]}")

# 5. Encontrar el mejor modelo
print(f"\nRESULTADOS FINALES:")

# Encontrar modelo con mayor accuracy promedio
best_mean_score = 0
best_model_name = ""

for name, scores in results.items():
    if scores.mean() > best_mean_score:
        best_mean_score = scores.mean()
        best_model_name = name

print(f"GANADOR: {best_model_name}")
print(f"Score: {best_mean_score:.4f}")

# 6. AnÃ¡lisis detallado de estabilidad
print(f"\nANÃLISIS DE ESTABILIDAD:")
for name, scores in results.items():
    stability = scores.std()

    if stability < 0.02:
        status = "MUY ESTABLE"
    elif stability < 0.05:
        status = "ESTABLE"
    else:
        status = "INESTABLE"

    print(f"   {name}: {status} (std: {stability:.4f})")

# 7. VisualizaciÃ³n comparativa
plt.figure(figsize=(12, 6))

# Boxplot de distribuciÃ³n de scores
plt.subplot(1, 2, 1)
plt.boxplot([results[name] for name in models.keys()],
           labels=[name.split()[0] for name in models.keys()])
plt.title('DistribuciÃ³n de Accuracy por Modelo')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

# Barplot de medias con error bars
plt.subplot(1, 2, 2)
names = list(models.keys())
means = [results[name].mean() for name in names]
stds = [results[name].std() for name in names]

plt.bar(range(len(names)), means, yerr=stds, capsize=5)
plt.xticks(range(len(names)), [name.split()[0] for name in names])
plt.title('Accuracy Promedio Â± DesviaciÃ³n EstÃ¡ndar')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```
### ğŸ† Torneo de Modelos - DiagnÃ³stico MÃ©dico

![Torneo de Modelos](../assets/ImgPractica5/imgP5.2.png)

- Este grÃ¡fico muestra la **distribuciÃ³n de la exactitud (accuracy)** obtenida mediante **validaciÃ³n cruzada** con tres modelos:
  - **Logistic Regression**: Modelo clÃ¡sico de regresiÃ³n, ideal para problemas lineales.
  - **Ridge Classifier**: Variante de la regresiÃ³n logÃ­stica con regularizaciÃ³n L2, Ãºtil para evitar el sobreajuste.
  - **Random Forest**: Modelo de ensemble basado en Ã¡rboles, robusto ante el sobreajuste y no requiere escalado.
- Se observa la **media** y la **desviaciÃ³n estÃ¡ndar** de los scores de cada modelo.
- Permite comparar la **estabilidad** de los modelos y decidir cuÃ¡l es el mÃ¡s adecuado para su implementaciÃ³n en diagnÃ³sticos mÃ©dicos.

---
### ğŸ† Torneo de Modelos - DiagnÃ³stico MÃ©dico

Modelos en competencia: **['Logistic Regression', 'Ridge Classifier', 'Random Forest']**

#### EvaluaciÃ³n con 5-Fold CV:

- **Logistic Regression**:
  - Resultado: 0.7618 Â± 0.0061
  - Scores: ['0.768', '0.768', '0.763', '0.755', '0.755']

- **Ridge Classifier**:
  - Resultado: 0.7509 Â± 0.0032
  - Scores: ['0.755', '0.746', '0.754', '0.749', '0.751']

- **Random Forest**:
  - Resultado: 0.7658 Â± 0.0064
  - Scores: ['0.775', '0.764', '0.771', '0.763', '0.757']

#### Resultados Finales:

- **GANADOR**: **Random Forest**
  - **Score**: 0.7658

#### AnÃ¡lisis de Estabilidad:

- **Logistic Regression**: **MUY ESTABLE** (std: 0.0061)
- **Ridge Classifier**: **MUY ESTABLE** (std: 0.0032)
- **Random Forest**: **MUY ESTABLE** (std: 0.0064)

Este anÃ¡lisis muestra el rendimiento y la estabilidad de los tres modelos, con **Random Forest** destacando como el ganador con el mejor score promedio. Todos los modelos fueron muy estables, con pequeÃ±as variaciones en sus scores.


## ğŸ“Š **ComparaciÃ³n de Modelos: VisualizaciÃ³n**

Visualizamos la comparaciÃ³n entre los diferentes modelos usando un **boxplot** para evaluar la distribuciÃ³n de la precisiÃ³n.

```python
plt.figure(figsize=(10, 6))
plt.boxplot([results[name] for name in models.keys()], labels=models.keys())
plt.title('ComparaciÃ³n de Modelos: ValidaciÃ³n Cruzada')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)
plt.show()
```
---

## ğŸ“ˆ **AnÃ¡lisis de Estabilidad y SelecciÃ³n de Modelos**

El **StratifiedKFold** mostrÃ³ ser el mÃ©todo mÃ¡s estable debido a la **preservaciÃ³n del balance de clases**. Esto hace que sea mÃ¡s adecuado para datasets con clases desbalanceadas, como es el caso de **abandono estudiantil**.

RecomendaciÃ³n: Usar **StratifiedKFold** para este dataset.

---
### ğŸš€ BONUS: OptimizaciÃ³n de HiperparÃ¡metros
#### ğŸ”§ Paso 6: GridSearchCV vs RandomizedSearchCV

La optimizaciÃ³n de hiperparÃ¡metros es crucial para mejorar el rendimiento del modelo. Comparamos dos mÃ©todos de bÃºsqueda de hiperparÃ¡metros para el **mejor modelo** de la competencia anterior.

- **MÃ©todo 1: GridSearchCV** (bÃºsqueda exhaustiva):
  - **ParÃ¡metros probados**: Diferentes combinaciones de hiperparÃ¡metros definidos en el espacio de bÃºsqueda.
  - **Resultado**: Se obtienen los mejores parÃ¡metros con el mejor score.
  - **Score**: EvaluaciÃ³n del modelo con validaciÃ³n cruzada.

- **MÃ©todo 2: RandomizedSearchCV** (bÃºsqueda aleatoria, mÃ¡s eficiente):
  - **ParÃ¡metros probados**: Solo una cantidad limitada de combinaciones aleatorias.
  - **Resultado**: Encuentra rÃ¡pidamente los mejores parÃ¡metros en menos tiempo.
  - **Score**: EvaluaciÃ³n del modelo con validaciÃ³n cruzada.

#### Resultados de la OptimizaciÃ³n de HiperparÃ¡metros:

- **GridSearchCV**:
  - Mejores parÃ¡metros: `{grid_search.best_params_}`
  - Mejor score: `{grid_search.best_score_:.4f}`

- **RandomizedSearchCV**:
  - Mejores parÃ¡metros: `{random_search.best_params_}`
  - Mejor score: `{random_search.best_score_:.4f}`

#### ComparaciÃ³n de eficiencia:
- **GridSearch probÃ³**: `{len(grid_search.cv_results_['params'])}` combinaciones.
- **RandomSearch probÃ³**: `{len(random_search.cv_results_['params'])}` combinaciones.

#### EvaluaciÃ³n del Modelo Final Optimizado:
- **Modelo Final** (utilizando GridSearchCV): `{final_scores.mean():.4f} Â± {final_scores.std():.4f}`

Este anÃ¡lisis nos muestra que **RandomizedSearchCV** es mÃ¡s eficiente al probar menos combinaciones, pero **GridSearchCV** proporciona una bÃºsqueda mÃ¡s exhaustiva, lo cual puede ser mÃ¡s Ãºtil si se requiere una optimizaciÃ³n mÃ¡s precisa.

[![ğŸ“˜ Abrir Notebook en Google Colab](https://img.shields.io/badge/Abrir%20Notebook-Google%20Colab-brightgreen?style=for-the-badge&logo=googlecolab&logoColor=white)](https://colab.research.google.com/drive/11HF94BcKLXSQA5HYoROzCNkrZ5YMThvc?usp=sharing)  

## ğŸ¯ **ReflexiÃ³n y Conclusiones**

- **Estabilidad**: **StratifiedKFold** mostrÃ³ mayor estabilidad y precisiÃ³n en los modelos.
- **Modelo Seleccionado**: El **Random Forest** fue el mejor clasificador, seguido por **Logistic Regression**.
- **MÃ©tricas Clave**: Se usaron mÃ©tricas como **accuracy** y **cross-validation** para medir el rendimiento de los modelos.

---






       
       
    
