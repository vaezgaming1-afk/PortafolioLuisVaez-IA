---
title: "üìù Tarea 5: Validaci√≥n y Selecci√≥n de Modelos - Fill in the Blanks"
date: 2025-09-07
number: 5
status: "Completado"
tags: [Machine Learning, Validaci√≥n de Modelos, Selecci√≥n de Modelos, Cross-validation]
notebook: https://colab.research.google.com/drive/1F0btMIVnncma9EYwR-2togcSPDW35evv
drive_viz: https://drive.google.com/drive/folders/1qglTzvqdFPrNMxUhH_MtQFcRrafXEG7x?usp=sharing
dataset: "Student Dropout and Academic Success"
time_est: "4 h"
time_spent: "‚Äî"
---

# üìù **TAREA 5: Validaci√≥n y Selecci√≥n de Modelos**

## üéØ **Objetivos B√°sicos**

En esta tarea, aprenderemos c√≥mo **validar** y **seleccionar modelos** de manera adecuada, utilizando **validaci√≥n cruzada** y comparando diferentes algoritmos para decidir cu√°l es el mejor para predecir el **abandono estudiantil** y el **√©xito acad√©mico**.

- Prevenir **data leakage** usando pipelines.
- Implementar **validaci√≥n cruzada** robusta.
- Comparar m√∫ltiples modelos de forma sistem√°tica.
- Interpretar m√©tricas de **estabilidad** y **selecci√≥n de modelos**.

## üìã **Lo que necesitas saber ANTES de empezar:**

Antes de comenzar, es importante que entiendas los siguientes conceptos:

- **Train/test split**: c√≥mo dividir un conjunto de datos en entrenamiento y prueba.
- Diferencia entre **regresi√≥n** y **clasificaci√≥n**.
- Uso b√°sico de **sklearn** y **pandas** para cargar y manejar datos.

---

## üéì **Dataset: Predicci√≥n de √âxito Estudiantil**

### **Contexto del negocio:**

**Problema:** Predecir el **abandono estudiantil** y el **√©xito acad√©mico** en la educaci√≥n superior.

**Objetivo:** Identificar estudiantes en riesgo para implementar **estrategias de apoyo**.

**Valor:** Reducir las tasas de abandono y mejorar la **retenci√≥n estudiantil**.

### **Caracter√≠sticas del Dataset:**

- **36 caracter√≠sticas** relacionadas con las variables **demogr√°ficas**, **acad√©micas** y **socioecon√≥micas** de los estudiantes.
- **Variable objetivo:** Predicci√≥n de si un estudiante **abandon√≥** o **se gradu√≥**.

### **Explorando el Dataset:**

1Ô∏è‚É£ **¬øCu√°ntas muestras y caracter√≠sticas tiene el dataset?**

- **Muestras:** 4424 estudiantes.
- **Caracter√≠sticas:** 36 variables (demogr√°ficas, acad√©micas y socioecon√≥micas).

2Ô∏è‚É£ **¬øQu√© tipos de variables incluye?**

- **Demogr√°ficas:** Estado civil, nacionalidad, g√©nero, edad al momento de la inscripci√≥n, ocupaci√≥n de los padres.
- **Acad√©micas:** Calificaciones previas, unidades curriculares aprobadas, desempe√±o acad√©mico en semestres anteriores.
- **Socioecon√≥micas:** Tasa de desempleo, inflaci√≥n, PIB.

3Ô∏è‚É£ **¬øLas clases est√°n balanceadas o desbalanceadas?**

- El dataset tiene un **desbalance** en las clases: m√°s estudiantes graduados que los que abandonaron.

4Ô∏è‚É£ **¬øQu√© significan las 2 categor√≠as objetivo?**

- **Dropout**: Estudiantes que han abandonado la educaci√≥n superior.
- **Graduate**: Estudiantes que han completado sus estudios con √©xito.

---

## üîß **Paso 1: Setup Inicial**

Antes de comenzar con la validaci√≥n cruzada, cargamos las bibliotecas necesarias y los datos:

```python
!pip install ucimlrepo
```

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from ucimlrepo import fetch_ucirepo
from sklearn.metrics import accuracy_score, classification_report

print("‚úÖ Setup completo!")
```

---

## üéì **Paso 2: Cargar y Explorar Datos**

Cargamos el **dataset de estudiantes** y comenzamos a explorar las caracter√≠sticas y clases para entender mejor los datos.

```python
# Cargar dataset de estudiantes desde UCI
student_data = fetch_ucirepo(id=697)

# Preparar datos
X = student_data.data.features
y = student_data.data.targets

print("Dataset: Student Dropout and Academic Success")
print(f"Estudiantes: {X.shape[0]}, Caracter√≠sticas: {X.shape[1]}")
print(f"Objetivo: Predecir {len(y.columns)} variable(s)")

# Explorar variable objetivo
target_col = y.columns[0]  # Primera columna objetivo
y_series = y[target_col]
print(f"\nVariable objetivo: {target_col}")
```

### **Distribuci√≥n de las clases**

Distribuci√≥n de la variable objetivo:

- **Graduate:** 2209 estudiantes (49.9%)
- **Dropout:** 1421 estudiantes (32.1%)
- **Enrolled:** 794 estudiantes (17.9%)

---

## üî¨ **Parte 1: Validaci√≥n Cruzada - Validaci√≥n Robusta**

Para evaluar el rendimiento del modelo y evitar **overfitting**, implementamos la validaci√≥n cruzada. Usaremos **KFold** y **StratifiedKFold**.

### **Configuraci√≥n del Pipeline y Validaci√≥n Cruzada**

```python
# Preparar datos para validaci√≥n
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
reverse_mapping = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}

# Si y_series contiene strings, convertir a n√∫meros
y_target = y_series.map(reverse_mapping)

X_features = X  # Caracter√≠sticas del dataset

# Crear pipeline con escalado de caracter√≠sticas y clasificaci√≥n
pipeline_robust = Pipeline([
    ('scaler', StandardScaler()),  # Escalado de caracter√≠sticas
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))  # Clasificador de regresi√≥n log√≠stica
])

# Crear KFold b√°sico
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
scores_kfold = cross_val_score(pipeline_robust, X_features, y_target, cv=kfold, scoring='accuracy')

print(f"\nKFOLD RESULTS:")
print(f"   Scores individuales: {scores_kfold}")
print(f"   Media: {scores_kfold.mean():.4f}")
print(f"   Desviaci√≥n est√°ndar: {scores_kfold.std():.4f}")
print(f"   Resultado: {scores_kfold.mean():.4f} ¬± {scores_kfold.std():.4f}")
```

---

## üî¨ **Parte 2: Comparaci√≥n de Modelos**

Evaluamos el rendimiento de varios modelos de clasificaci√≥n para ver cu√°l tiene un mejor desempe√±o en el problema de **abandono estudiantil**:

```python
# Importar librer√≠as necesarias
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt

# Crear un pipeline con diferentes clasificadores
models = {
    'Logistic Regression': Pipeline([('scaler', StandardScaler()), ('classifier', LogisticRegression(max_iter=1000, random_state=42))]),
    'Ridge Classifier': Pipeline([('scaler', StandardScaler()), ('classifier', RidgeClassifier(alpha=1.0, random_state=42))]),
    'Random Forest': Pipeline([('classifier', RandomForestClassifier(n_estimators=100, random_state=42))])
}

# Evaluar cada modelo con validaci√≥n cruzada
results = {}
for name, model in models.items():
    scores = cross_val_score(model, X_features, y_target, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), scoring='accuracy')
    results[name] = scores
    print(f"{name}: {scores.mean():.4f} ¬± {scores.std():.4f}")

# Encontrar el modelo con el mejor rendimiento
best_model = max(results, key=lambda k: results[k].mean())
print(f"\nEl mejor modelo es: {best_model}")
```

---

## üìä **Comparaci√≥n de Modelos: Visualizaci√≥n**

Visualizamos la comparaci√≥n entre los diferentes modelos usando un **boxplot** para evaluar la distribuci√≥n de la precisi√≥n.

```python
plt.figure(figsize=(10, 6))
plt.boxplot([results[name] for name in models.keys()], labels=models.keys())
plt.title('Comparaci√≥n de Modelos: Validaci√≥n Cruzada')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)
plt.show()
```

---

## üìà **An√°lisis de Estabilidad y Selecci√≥n de Modelos**

El **StratifiedKFold** mostr√≥ ser el m√©todo m√°s estable debido a la **preservaci√≥n del balance de clases**. Esto hace que sea m√°s adecuado para datasets con clases desbalanceadas, como es el caso de **abandono estudiantil**.

Recomendaci√≥n: Usar **StratifiedKFold** para este dataset.

---

## üéØ **Reflexi√≥n y Conclusiones**

- **Estabilidad**: **StratifiedKFold** mostr√≥ mayor estabilidad y precisi√≥n en los modelos.
- **Modelo Seleccionado**: El **Random Forest** fue el mejor clasificador, seguido por **Logistic Regression**.
- **M√©tricas Clave**: Se usaron m√©tricas como **accuracy** y **cross-validation** para medir el rendimiento de los modelos.

---




       
       
    
