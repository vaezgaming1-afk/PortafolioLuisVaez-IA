<h1 align="center"> Inteligencia para la RetenciÃ³n: PredicciÃ³n de Churn en Telecom con Pipelines Robustos y EvaluaciÃ³n Avanzada ğŸ“¡ğŸ”¥</h1>

![TelcoChurnBanner](../assets/ImgPractica5/img5.2.1.png)

<p align="center">
  <em>Analizando patrones de abandono en clientes telecom para anticipar bajas y optimizar estrategias de retenciÃ³n utilizando modelos modernos de clasificaciÃ³n.</em>
</p>

ğŸ·ï¸ **Etiquetas RÃ¡pidas**  
`#TelcoChurn` `#ClasificaciÃ³nBinaria` `#Pipelines` `#MLMetrics` `#ModelComparison` `#CustomerAnalytics`

---

## ğŸš€ Accesos Directos Importantes

<div align="center">

<a href="https://colab.research.google.com/drive/XXXXX_TU_ENLACE_XXXXX">
  <img src="https://img.shields.io/badge/Abrir%20Notebook-Google%20Colab-brightgreen?style=for-the-badge&logo=googlecolab&logoColor=white" alt="Abrir Notebook en Colab" />
</a>

&nbsp;

<a href="https://drive.google.com/drive/folders/XXXXX_TU_DRIVE_XXXXX">
  <img src="https://img.shields.io/badge/Visualizaciones-Google%20Drive-blue?style=for-the-badge&logo=google-drive&logoColor=white" alt="Ver visualizaciones en Drive" />
</a>

</div>

---

# ğŸ§  **Resumen Ejecutivo**

ğŸ¯ **Objetivo General:**  
Predecir la probabilidad de abandono (churn) en clientes de telecomunicaciones utilizando modelos de clasificaciÃ³n binaria, pipelines reproducibles y una baterÃ­a completa de mÃ©tricas mÃ¡s allÃ¡ del accuracy.

ğŸ“Œ **Hallazgos clave preliminares:**

- Dataset con **7 043 clientes** y **21 variables** relacionadas a:
  - servicios contratados (internet, lÃ­neas, addons),
  - tipo de contrato,
  - forma de pago y cargos mensuales,
  - permanencia.
- El target **Churn (Yes/No)** presenta un desbalance moderado, lo que lo convierte en un escenario ideal para:
  - `StratifiedKFold`
  - MÃ©tricas sensibles al desbalance: F1, ROC-AUC, Precision-Recall
  - ComparaciÃ³n estable entre modelos
- Es un caso perfecto para modelar un **"riesgo de abandono"**, imitando pipelines reales usados en telecom.

ğŸ“ˆ **Resultado preliminar:**  
Modelos lineales como **LogisticRegression** son interpretables y sorprendentemente competitivos. Ãrboles y ensembles (**RandomForest, GradientBoosting, XGBoost**) capturan interacciones no lineales y suelen liderar en ROC-AUC, aunque con mayor varianza. El pipeline unificado asegura comparaciones justas y sin fugas de datos.

---

# ğŸ¯ **Objetivos EspecÃ­ficos**

| Objetivo                                                                           | Estado |
|------------------------------------------------------------------------------------|--------|
| Cargar y explorar el dataset Telco (IBM)                                          | âœ…      |
| Convertir target a binario: `Churn_Flag`                                          | âœ…      |
| Separar columnas numÃ©ricas vs categÃ³ricas                                         | â³      |
| Construir pipeline completo con OneHotEncoder & StandardScaler                    | â³      |
| Entrenar modelos: LogisticReg, RandomForest, XGBClassifier                        | â³      |
| Evaluar con multiple-metrics via `cross_validate` y `StratifiedKFold(n=5)`        | â³      |
| Comparar estabilidad de modelos (media Â± std por mÃ©trica)                         | â³      |
| Elaborar comentario tÃ©cnico sobre cuÃ¡l modelo gana y por quÃ©                      | â³      |

---

# ğŸ“… **Actividades y Tiempos**

| Actividad                                                     | Estimado | Real  | Nota                                                           |
|---------------------------------------------------------------|----------|-------|----------------------------------------------------------------|
| Carga + limpieza inicial del dataset                          | 20 m     | â€”     | ConversiÃ³n de Churn y revisiÃ³n de columnas                     |
| AnÃ¡lisis exploratorio (EDA)                                   | 30 m     | â€”     | Distribuciones, contrato, cargos mensuales, churn rate         |
| PreparaciÃ³n del pipeline (num/cat + OHE + scaler)             | 35 m     | â€”     | Similar a flujos corporativos de telcos                        |
| Entrenamiento: baseline + modelos avanzados                   | 45 m     | â€”     | Logistic â†’ RF â†’ XGB                                            |
| ValidaciÃ³n cruzada con mÃºltiples mÃ©tricas                     | 35 m     | â€”     | Accuracy, Precision, Recall, F1, ROC-AUC, PRC                  |
| ComparaciÃ³n y anÃ¡lisis de estabilidad                         | 25 m     | â€”     | Tabla final tipo â€œtorneo de modelosâ€                           |
| ReflexiÃ³n final y recomendaciones                             | 15 m     | â€”     | AplicaciÃ³n real en retenciÃ³n y marketing                       |

ğŸ•’ **Total estimado:** 3 h 00 m

---

# ğŸ› ï¸ **Feature Engineering Aplicado**

| TÃ©cnica                          | DescripciÃ³n                                                                 |
|----------------------------------|------------------------------------------------------------------------------|
| **CodificaciÃ³n categÃ³rica**       | OneHotEncoder para todas las columnas categÃ³ricas (`handle_unknown="ignore"`) |
| **EstandarizaciÃ³n**               | StandardScaler para las variables numÃ©ricas                                   |
| **Nueva variable objetivo**       | `Churn_Flag = (Churn == "Yes").astype(int)`                                   |
| **Limpieza inicial**              | ConversiÃ³n de columnas numÃ©ricas mal tipificadas (ej: `TotalCharges`)         |
| **Balance & validaciÃ³n**         | Uso obligatorio de `StratifiedKFold` para preservar proporciones de churn     |

---

# âš™ï¸ **Modelos Considerados**

#### ğŸ”¹ **Baseline**
- `DummyClassifier`  
Ideal para medir mejora real sobre un modelo trivial.

#### ğŸ”¸ **Modelos Principales**
- `LogisticRegression`  
  - Interpretabilidad total y buen rendimiento con regularizaciÃ³n.
- `RandomForestClassifier`  
  - Captura no linealidades y relaciones de interacciÃ³n.
- `XGBClassifier` *(opcional pero recomendado si quieres ir â€œfull proâ€)*  
  - Alta performance en datasets tabulares.
  - Suele liderar en ROC-AUC, especialmente con desbalance moderado.

#### ğŸ”¸ **EvaluaciÃ³n Avanzada**
- `cross_validate` con mÃºltiples mÃ©tricas:  
  `["accuracy", "precision", "recall", "f1", "roc_auc"]`
- ComparaciÃ³n de **media Â± desviaciÃ³n estÃ¡ndar** por modelo.
- AnÃ¡lisis de **estabilidad**:  
  QuiÃ©n gana, quiÃ©n es mÃ¡s consistente, quiÃ©n es mÃ¡s variable.

---

