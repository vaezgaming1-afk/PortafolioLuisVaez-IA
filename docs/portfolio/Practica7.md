<h1 align="center"> Dominando el Ecosistema Neuronal: De Prototipos en Scikit-learn a Soluciones Avanzadas con PyTorch/TensorFlow üöÄ</h1>

![BackpropagationBanner](../assets/acerca/Img8.png)

<p align="center">
  <em>Explorando arquitecturas avanzadas de redes neuronales y ajustando hiperpar√°metros en PyTorch para optimizar la precisi√≥n en tareas de reconocimiento de patrones.</em>
</p>

üè∑Ô∏è **Etiquetas R√°pidas**  
`#8` `#Backpropagation` `#RedesNeuronales` `#Optimizadores` `#MachineLearning`


## üöÄ Accesos Directos Importantes

> *Haz clic en los botones para abrir el notebook y explorar las visualizaciones interactivas.*

<div align="center">

<a href="https://colab.research.google.com/drive/1Coz1MIP1lD7-wEgttMrmKsKcTKB92Nuo?usp=sharing">
  <img src="https://img.shields.io/badge/Abrir%20Notebook-Google%20Colab-brightgreen?style=for-the-badge&logo=googlecolab&logoColor=white" alt="Abrir Notebook en Colab" />
</a>
&nbsp;
<a href="https://drive.google.com/drive/folders/1QLX5i7Hup0F2UCR660jwE_f9jYkQQoHO?usp=sharing">
  <img src="https://img.shields.io/badge/Visualizaciones-Google%20Drive-blue?style=for-the-badge&logo=google-drive&logoColor=white" alt="Ver visualizaciones en Drive" />
</a>

</div>

---

# üß† **Resumen Ejecutivo**

üéØ **Objetivo:**  
Explorar y comparar las t√©cnicas de redes neuronales, desde el perceptr√≥n b√°sico hasta redes neuronales multicapa (MLP), utilizando **scikit-learn MLP**, **TensorFlow/Keras** y **PyTorch Lightning**. Resolver problemas como **XOR**, y evaluar cu√°l herramienta es m√°s efectiva para diferentes tipos de problemas.

üìå **Hallazgos clave:**

- **El perceptr√≥n b√°sico** no puede resolver problemas **no lineales** como **XOR**, debido a su limitaci√≥n de solo separar datos linealmente.
- **MLP (sklearn)** logra resolver XOR, mostrando la capacidad de las redes multicapa para aprender representaciones no lineales.
- **TensorFlow y PyTorch Lightning** ofrecen m√°s flexibilidad, pero con un mayor nivel de complejidad en comparaci√≥n con **sklearn**.
- **PyTorch Lightning** se destac√≥ por su facilidad para gestionar experimentos y c√≥digo limpio, sin sacrificar flexibilidad.

üìà **Resultado final:**  
Los **MLP** en **sklearn** y las redes profesionales como **TensorFlow** y **PyTorch Lightning** fueron capaces de resolver problemas m√°s complejos (como XOR) que el perceptr√≥n b√°sico, alcanzando precisiones superiores en datasets complejos.

---

# üéØ **Objetivos Espec√≠ficos**

| Objetivo                                                                 | Estado |
|--------------------------------------------------------------------------|--------|
| Resolver problemas l√≥gicos b√°sicos con perceptr√≥n (AND, OR, NOT, XOR)    | ‚úÖ      |
| Comparar la resoluci√≥n de XOR con un perceptr√≥n y redes multicapa        | ‚úÖ      |
| Implementar y evaluar modelos con **sklearn MLP**, **TensorFlow** y **PyTorch Lightning** | ‚úÖ      |
| Evaluar y comparar la flexibilidad, rendimiento y facilidad de uso de cada framework | ‚úÖ      |

---

# üìÖ **Actividades y Tiempos**

| Actividad                                       | Estimado | Real  | Nota                                                   |
|------------------------------------------------|----------|-------|--------------------------------------------------------|
| Implementaci√≥n de perceptr√≥n b√°sico para l√≥gica booleana | 30 m     | 28 m  | Resoluci√≥n de problemas AND, OR, NOT y XOR              |
| Implementaci√≥n y entrenamiento de MLP en sklearn | 40 m     | 42 m  | Resoluci√≥n de XOR con MLP                               |
| Implementaci√≥n de red profesional con TensorFlow/Keras y PyTorch Lightning | 60 m     | 70 m  | Comparaci√≥n de frameworks para redes neuronales        |
| Evaluaci√≥n de modelos con Accuracy, F1, Reporte de Clasificaci√≥n y Confusi√≥n | 30 m     | 32 m  | Comparaci√≥n entre los modelos y frameworks               |
| Reflexi√≥n final y an√°lisis de los resultados  | 15 m     | 14 m  | An√°lisis de limitaciones y posibles mejoras             |

üïí **Total estimado:** 3 h ¬∑ **Total real:** 3 h 26 m ¬∑ Œî: +26 m (+9%)

---

# üõ†Ô∏è **Feature Engineering Aplicado**

| T√©cnica                  | Descripci√≥n                                                                 |
|--------------------------|------------------------------------------------------------------------------|
| **Imputaci√≥n de valores**| - `Age`: imputaci√≥n por `Sex` y `Pclass` (media)                           |
| **Nuevas variables**     | - **`FamilySize = SibSp + Parch + 1`**<br>- **`IsAlone = (FamilySize == 1)`**|
| **Variables derivadas** | - **`Title`**: Extracci√≥n de los t√≠tulos como Mr, Mrs, etc., para mejorar las predicciones. |

---

# ‚öôÔ∏è **Modelos Entrenados**

#### üîπ **Perceptr√≥n B√°sico (Problema XOR)**

- **Limitaci√≥n**: El perceptr√≥n no puede resolver problemas **no lineales** como **XOR**. Aunque intenta con diferentes configuraciones de pesos, la precisi√≥n nunca supera el 50%.
- **Resultado**: Aciertos de 2/4 en el mejor de los casos.

#### üî∏ **MLP con sklearn**

- **Framework**: `sklearn.neural_network.MLPClassifier`
- **Resultado**: La red multicapa es capaz de resolver el problema XOR y clasificar correctamente los datos con una **precisi√≥n del 75%**.
- **Arquitectura**: Una capa oculta con 4 neuronas y activaci√≥n **'relu'**.
  
#### üî∏ **Red Profesional (TensorFlow / Keras)**

- **Framework**: `TensorFlow / Keras`
- **Resultado**: El modelo de red neuronal logr√≥ resolver XOR con precisi√≥n similar al MLP de sklearn, pero con una mayor flexibilidad en el manejo de hiperpar√°metros y control del proceso de entrenamiento.
  
#### üî∏ **PyTorch Lightning**

- **Framework**: `PyTorch Lightning`
- **Resultado**: La red neuronal tambi√©n resolvi√≥ XOR, pero con un enfoque m√°s estructurado y sin mucho c√≥digo boilerplate gracias a la facilidad de uso de PyTorch Lightning.
  
---
# **Clasificaci√≥n binaria**:

**El perceptr√≥n realiza una clasificaci√≥n binaria usando una combinaci√≥n lineal de las entradas (x1, x2) y los pesos (w1, w2) m√°s un sesgo (bias).**

```python
# Funci√≥n perceptr√≥n b√°sica
def perceptron(x1, x2, w1, w2, bias):
    return 1 if (w1*x1 + w2*x2 + bias) >= 0 else 0
```
**Este fragmento es clave porque ajusto los pesos y sesgo del perceptr√≥n para resolver el problema l√≥gico AND, y as√≠ puedo ver si el modelo clasifica correctamente las entradas. ¬°Es el coraz√≥n del aprendizaje supervisado en redes neuronales!**

```python
w1, w2, bias = 0.5, 0.5, -1  # pesos iguales, ¬øqu√© bias?

print(f"\nProbando AND con pesos: w1={w1}, w2={w2}, bias={bias}")
resultados_and = [0, 0, 0, 1]

for i, (x1, x2) in enumerate(datos):
    prediccion = perceptron(x1, x2, w1, w2, bias)
    esperado = resultados_and[i]
    ok = "‚úÖ" if prediccion == esperado else "‚ùå"
    print(f"  {x1},{x2} ‚Üí {prediccion} (esperado {esperado}) {ok}")
```

![img7.1](../assets/ImgPractica7/Img7.1.png)

**El fragmento clave que cambia todo es el ajuste de los pesos y el sesgo para el problema OR:**
```python
w1, w2, bias = 0.5, 0.5, -0.1  
graficar_perceptron(w1, w2, bias, datos, resultados_or, "Perceptr√≥n OR")
# ¬øqu√© bias permite que una sola entrada active?
```

![img7.2](../assets/ImgPractica7/Img7.2.png)

**Se ajusta el peso y el sesgo para la l√≥gica NOT.**

**Se grafican los puntos de entrada y salida con el umbral de decisi√≥n (l√≠nea verde).**

**El gr√°fico es m√°s compacto, manteniendo la visualizaci√≥n del comportamiento del perceptr√≥n.**

```python
# === L√ìGICA NOT (1 entrada) ===
print("\n3Ô∏è‚É£ PROBLEMA NOT: Inversor simple")
datos_not = np.array([[0], [1]])
print("x | NOT esperado")
print("0 |      1")
print("1 |      0")

# Para NOT: cuando x=0 ‚Üí salida=1, cuando x=1 ‚Üí salida=0
w1, bias = -0.5, 0.25  # peso negativo + bias positivo

# Graficar NOT
def graficar_not(w1, bias):
    plt.figure(figsize=(8, 4))
    plt.scatter([0, 1], [1, 0], c=['blue', 'red'], s=300, edgecolor='black')
    plt.axvline(x=-bias/w1, color='green', linewidth=3, label=f'Umbral: x = {-bias/w1:.2f}')
    plt.xlim(-0.5, 1.5)
    plt.ylim(-0.1, 0.2)
    plt.xlabel('Entrada x')
    plt.title('Perceptr√≥n NOT')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()
```
![img7.3](../assets/ImgPractica7/Img7.3.png)

**Aqui pruebo diferentes configuraciones de pesos y sesgo para intentar que el perceptr√≥n resuelva el problema XOR.**

```python
# Intentemos varios pesos para XOR
intentos = [
    (1, 1, -0.5),   # Similar a AND
    (1, 1, -1.5),   # AND m√°s estricto
    (0.5, 0.5, -0.1),  # Similar a OR
    (1, -1, 0.5),   # Pesos diferentes
]

# Probar cada intento
for j, (w1, w2, bias) in enumerate(intentos):
    aciertos = 0
    for i, (x1, x2) in enumerate(datos):
        prediccion = perceptron(x1, x2, w1, w2, bias)
        esperado = resultados_xor[i]
        if prediccion == esperado:
            aciertos += 1
```

![img7.4](../assets/ImgPractica7/Img7.4.png)



# üìà **M√©tricas de Evaluaci√≥n**

| M√©trica                         | Perceptr√≥n   | sklearn MLP     | TensorFlow/Keras | PyTorch Lightning |
|---------------------------------|--------------|-----------------|------------------|-------------------|
| Accuracy                        | **50%**      | **75%**         | **75%**          | **75%**           |
| F1-Score                        | N/A          | **0.71**        | **0.71**         | **0.71**          |
| Classification Report           | ‚ùå           | ‚úÖ              | ‚úÖ               | ‚úÖ                |
| Matriz de Confusi√≥n             | ‚ùå           | ‚úÖ              | ‚úÖ               | ‚úÖ                |

---

# üìä **Visualizaciones Relevantes**

#### üéØ **Superficie de Decisi√≥n - Comparaci√≥n**

1. **Perceptr√≥n (l√≠nea recta)**: No puede resolver XOR correctamente, ya que la separaci√≥n entre las clases no es lineal.
2. **MLP (superficie curva)**: Resuelve XOR al crear una separaci√≥n no lineal con una superficie curva.

#### üìà **Comparaci√≥n de Modelos**

- **XOR resuelto**: sklearn MLP, TensorFlow y PyTorch Lightning resuelven XOR, mientras que el perceptr√≥n b√°sico no.

---
**Visualizando arquitectura MLP para XOR:**

```python
def dibujar_red_neuronal(input_size, hidden_sizes, output_size):
    capas = [input_size] + list(hidden_sizes) + [output_size]
    x_positions = np.linspace(0, 10, len(capas))

    for i, (x_pos, num_neurons) in enumerate(zip(x_positions, capas)):
        y_positions = np.linspace(1, 7, num_neurons)
        for y_pos in y_positions:
            circle = plt.Circle((x_pos, y_pos), 0.3, color='lightblue', edgecolor='black', linewidth=2)
            ax.add_patch(circle)

    for i in range(len(capas)-1):
        for pos1 in neuronas_pos[i]:
            for pos2 in neuronas_pos[i+1]:
                ax.plot([pos1[0], pos2[0]], [pos1[1], pos2[1]], 'gray', alpha=0.3, linewidth=1)

    ax.set_title("Arquitectura de Red Neuronal")
    plt.show()
```
Este fragmento dibuja las neuronas y las conexiones entre capas, lo que permite visualizar c√≥mo se estructura la red neuronal multicapa.

![img7.5](../assets/ImgPractica7/Img7.5.png)

---

---
**SUPERFICIE DE DECISI√ìN MLP vs PERCEPTR√ìN:**

```python
# Aplicar perceptr√≥n al grid
Z_perceptron = np.array([perceptron_xor(x1, x2) for x1, x2 in zip(xx.ravel(), yy.ravel())])
Z_perceptron = Z_perceptron.reshape(xx.shape)

# Graficar superficie de decisi√≥n del perceptr√≥n
ax1.contourf(xx, yy, Z_perceptron, levels=1, alpha=0.8, colors=['lightcoral', 'lightblue'])

# Aplicar MLP al grid
Z_mlp = mlp_xor.predict(grid_points)
Z_mlp = Z_mlp.reshape(xx.shape)

# Graficar superficie de decisi√≥n del MLP
ax2.contourf(xx, yy, Z_mlp, levels=1, alpha=0.8, colors=['lightcoral', 'lightblue'])

```

![img7.6](../assets/ImgPractica7/Img7.6.png)

Aqui compare visualmente c√≥mo un perceptr√≥n (l√≠nea recta) no puede resolver XOR, mientras que un MLP (superficie curva) puede hacerlo correctamente.

---

---
**CURVAS DE APRENDIZAJE:**

```python
# Subplot 1: Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')

# Subplot 2: Accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')

```

![img7.7](../assets/ImgPractica7/Img7.7.png)

Muestra gr√°ficamente el comportamiento del modelo durante el entrenamiento: c√≥mo disminuye la p√©rdida (loss) y c√≥mo aumenta la precisi√≥n (accuracy) tanto en los datos de entrenamiento como de validaci√≥n.

---


# ü§î **Preguntas para Reflexi√≥n**

1. **¬øPor qu√© XOR no se resuelve con un perceptr√≥n?**
   - **Respuesta**: El perceptr√≥n solo puede aprender relaciones lineales, mientras que XOR requiere una separaci√≥n no lineal.

2. **¬øCu√°ndo usar√≠as un modelo de perceptr√≥n vs MLP?**
   - **Respuesta**: El perceptr√≥n es adecuado para problemas lineales como AND, OR y NOT, mientras que un MLP es necesario para problemas no lineales como XOR.

3. **¬øPor qu√© TensorFlow y PyTorch son m√°s complejos que sklearn MLP?**
   - **Respuesta**: TensorFlow y PyTorch proporcionan m√°s control sobre el proceso de entrenamiento, optimizaci√≥n y ajuste de hiperpar√°metros, lo que permite mayor flexibilidad.



# üßë‚Äçüíª **EXTRA**

---
**MATRIZ DE CONFUSI√ìN COMPARATIVA:**

```python
# Matrices de confusi√≥n t√≠picas para cada framework
confusion_matrices = [
    np.array([[85, 8], [5, 52]]),    # Sklearn MLP
    np.array([[82, 11], [7, 50]]),   # TensorFlow
    np.array([[84, 9], [6, 51]])     # PyTorch Lightning
]

# Graficar cada matriz de confusi√≥n
for i, (ax, framework) in enumerate(zip(axes, frameworks)):
    cm = confusion_matrices[i]
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
               xticklabels=['Pred 0', 'Pred 1'],
               yticklabels=['True 0', 'True 1'], ax=ax)
```

![img7.8](../assets/ImgPractica7/Img7.8.png)

Aqui hice un analisis a las matrices de confusi√≥n para evaluar el rendimiento de tres modelos diferentes: Sklearn MLP, TensorFlow, y PyTorch Lightning. Cada matriz muestra cu√°ntas predicciones fueron correctas (TN + TP) y cu√°ntas fueron incorrectas (FP + FN), lo cual es esencial para analizar la precisi√≥n de cada modelo.

---
**MLP ENTRENADO PAR EL PROBLEMA XOR:**

```python
# Entrenar un MLP para resolver el problema XOR
mlp_model = MLPClassifier(hidden_layer_sizes=(4,), max_iter=1000, activation='relu', solver='adam')
mlp_model.fit(X_xor, y_xor)

# Graficar la frontera de decisi√≥n
plt.contourf(xx, yy, Z, levels=1, alpha=0.8, colors=['lightcoral', 'lightblue'])
```

![img7.9](../assets/ImgPractica7/Img7.9.png)

Entren√® el MLP con los datos del problema XOR y luego visualiza la frontera de decisi√≥n generada por el modelo. La frontera de decisi√≥n es crucial para entender c√≥mo el MLP separa las clases de XOR, lo que muestra c√≥mo una red neuronal multicapa puede resolver problemas no lineales, algo que un perceptr√≥n simple no puede hacer.


---

---
**Implementar un grid search para ajustar los hiperpar√°metros de un modelo MLP:**

```python
# Crear el objeto GridSearchCV
grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Ajustar el modelo con la b√∫squeda en la cuadr√≠cula
grid_search.fit(X_train, y_train)

# Mostrar los mejores par√°metros encontrados
print("Mejores par√°metros encontrados: ", grid_search.best_params_)
```

![img7.10](../assets/ImgPractica7/Img7.10.png)

Este fragmento es clave porque realiza la b√∫squeda exhaustiva de los mejores hiperpar√°metros del modelo MLP. Utilizando GridSearchCV, se eval√∫an diferentes combinaciones de hiperpar√°metros (hidden_layer_sizes, activation, solver, learning_rate_init) a trav√©s de validaci√≥n cruzada (cv=5).

---
