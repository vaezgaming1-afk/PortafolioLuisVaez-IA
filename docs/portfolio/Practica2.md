# üöÄ **Pr√°ctica 2: Feature Engineering + Modelo Base**

<span class="pill">Completado</span>
<span class="pill">#2</span>
<span class="pill">Feature Engineering</span>
<span class="pill">Titanic</span>
<span class="pill">Machine Learning</span>
<span class="pill">Modelo Base</span>

[**Ver Notebook en Google Colab**](https://colab.research.google.com/drive/1xOjYjaSN2DM7szuRU7wsep-l2vCXaDSR?usp=sharing)  
[**Ver Visualizaciones en Google Drive**](https://drive.google.com/drive/folders/1WMHuuZMkUeXZYrEZBdhwqgbqwMg7vktG?usp=drive_link)  

---

## üèÜ **Resumen Ejecutivo**

En esta pr√°ctica, **trabajamos con el dataset Titanic**, aplicamos **Feature Engineering b√°sico** y entrenamos un modelo de **Regresi√≥n Log√≠stica**. Luego, comparamos el rendimiento del modelo con un **DummyClassifier** como baseline.

**Objetivo:** Realizar un **an√°lisis exploratorio de caracter√≠sticas** y construir un modelo b√°sico.  
**Hallazgos clave:** La **variable 'Sexo'** es crucial para la supervivencia, y el **modelo de Regresi√≥n Log√≠stica** super√≥ ampliamente al **DummyClassifier**.  
**Resultado final:** El modelo base y los nuevos features mostraron mejoras en la predicci√≥n de la supervivencia.

---

## üéØ **Objetivos de la Pr√°ctica**

- [x] Aplicar **Feature Engineering** para mejorar la informaci√≥n del dataset Titanic.  
- [x] Entrenar un **modelo base** usando **Regresi√≥n Log√≠stica**.  
- [x] Comparar el rendimiento entre un **modelo base** y un **modelo entrenado**.
- [x] **Evaluar** el modelo con m√©tricas como **accuracy**, **classification report**, y **confusion matrix**.

---

## üìä **Modelos Entrenados**

1. **Modelo Base (DummyClassifier):**  
   Se entren√≥ un modelo DummyClassifier como baseline para comparar el rendimiento con el modelo real.

2. **Modelo de Regresi√≥n Log√≠stica:**  
   Con el uso de los nuevos features obtenidos a trav√©s del Feature Engineering, el modelo de Regresi√≥n Log√≠stica mostr√≥ una mejora significativa en el rendimiento en comparaci√≥n con el DummyClassifier.

---

## üìà **M√©tricas de Evaluaci√≥n**

- **Accuracy:** El modelo de Regresi√≥n Log√≠stica super√≥ al DummyClassifier con una precisi√≥n m√°s alta.  
- **Classification Report:** Se utilizaron m√©tricas como Precision, Recall y F1-Score para evaluar la efectividad del modelo.  
- **Confusion Matrix:** Se gener√≥ una matriz de confusi√≥n para analizar los verdaderos positivos, falsos negativos y falsos positivos del modelo.

---

## üìÖ **Pr√≥ximos Pasos**

- [ ] **Optimizar el Modelo:** Mejorar el modelo con m√°s caracter√≠sticas y probar otros algoritmos de clasificaci√≥n.  
- [ ] **Ajuste de Hiperpar√°metros:** Probar t√©cnicas como GridSearchCV para encontrar los mejores hiperpar√°metros para el modelo.  
- [ ] **Exploraci√≥n Adicional:** Experimentar con otros tipos de Feature Engineering y t√©cnicas avanzadas como la selecci√≥n de caracter√≠sticas.

## ‚è±Ô∏è **Actividades y tiempos estimados**
| Actividad                                   | Estimado | Real | Nota |
|---|---:|---:|---|
| Configuraci√≥n inicial en **Google Colab**    | 30 m | **28 m** | Configuraci√≥n y carga de datos desde Kaggle. |
| Preprocesamiento y **Feature Engineering**   | 40 m | **42 m** | Manejo de valores faltantes y creaci√≥n de nuevas caracter√≠sticas. |
| Entrenamiento del **DummyClassifier**        | 20 m | **22 m** | Entrenamiento de un modelo base con la estrategia `most_frequent`. |
| **Entrenamiento de Regresi√≥n Log√≠stica**     | 30 m | **35 m** | Entrenamiento de modelo y optimizaci√≥n b√°sica de par√°metros. |
| Evaluaci√≥n de modelos y comparaci√≥n          | 30 m | **32 m** | Comparaci√≥n entre **DummyClassifier** y **Logistic Regression**. |
| Reflexi√≥n y discusi√≥n de preguntas           | 15 m | **14 m** | An√°lisis de errores y patrones en los datos. |

> **Totales** ‚Äî Estimado: **3 h** ¬∑ Real: **3 h 13 m** ¬∑ Œî: **+13 m** (**+6%**).

---

## üí° **Desarrollo: Feature Engineering**

### 1. **Manejo de valores faltantes:**
   - **Embarked:** Se reemplaza por el valor m√°s frecuente.
   - **Fare:** Se completa con la **mediana** de la tarifa.
   - **Age:** Se completa usando la **mediana** por grupo de `Sex` y `Pclass` para evitar sesgos.

### 2. **Creaci√≥n de nuevas caracter√≠sticas:**
   - **FamilySize:** La combinaci√≥n de `SibSp` (hermanos/esposos) y `Parch` (padres/hijos), para reflejar el tama√±o de la familia.
   - **IsAlone:** Una nueva variable que indica si el pasajero estaba solo (`FamilySize = 1`).
   - **Title:** Extracci√≥n del t√≠tulo del nombre (Sr, Mrs, Miss, etc.) para capturar categor√≠as de clase y edad.
   - **Rare Titles:** Agrupaci√≥n de t√≠tulos poco frecuentes bajo la categor√≠a 'Rare' para simplificar el modelo.

---

## üßë‚Äçüè´ **Modelo base vs Modelo entrenado**

### **Modelo base: DummyClassifier**
El **DummyClassifier** es un modelo muy simple que sirve como referencia b√°sica. En este caso, utilizamos la estrategia **most_frequent**, que predice siempre la clase m√°s frecuente (en este caso, que no sobrevivi√≥).

- **Accuracy:** 62%  
- **Prop√≥sito:** Ver qu√© tan bien lo hace un modelo "tonto" comparado con un modelo entrenado.

### **Modelo entrenado: Regresi√≥n Log√≠stica**
La **Regresi√≥n Log√≠stica** es un modelo muy com√∫n para problemas de clasificaci√≥n binaria. En este caso, usamos **LogisticRegression** de **scikit-learn** con un **solver liblinear** para optimizar los par√°metros.

- **Accuracy:** 78.5%  
- **F1-Score:** 0.73  
- **Mejora significativa sobre el DummyClassifier.**

---

### Visualizaci√≥n de relaciones en el dataset Titanic

1. **Gr√°fico de supervivencia por clase y sexo:**
   ![Matriz de Confusi√≥n - Regresi√≥n Log√≠stica](../../assets/ImgPractica2/imgP2.1.png)
   - **Relaci√≥n entre variables clave**: Sexo y clase, destacando la mayor tasa de supervivencia para las mujeres y los pasajeros de 1¬™ clase.

2. **Histograma de edad de los pasajeros:**
   ![Gr√°fico de Precisi√≥n: DummyClassifier vs Logistic Regression](../../assets/ImgPractica2/imgP2.2.png)
   - **Distribuci√≥n de edades**: Mayor concentraci√≥n de adultos j√≥venes.

[**Ver todas las visualizaciones aqu√≠**](https://drive.google.com/drive/folders/1WMHuuZMkUeXZYrEZBdhwqgbqwMg7vktG?usp=drive_link)

---
# üöÄ **Explora el Notebook Interactivo en Google Colab** üéì

Haz clic en el siguiente **bot√≥n** para acceder al **notebook** interactivo y realizar el an√°lisis directamente en Google Colab:

[![Ver Notebook en Google Colab](https://img.shields.io/badge/Accede%20al%20Notebook%20en%20Google%20Colab-brightgreen?style=for-the-badge&logo=googlecolab)](https://colab.research.google.com/drive/1xOjYjaSN2DM7szuRU7wsep-l2vCXaDSR?usp=sharing)

> **¬°Haz clic para empezar a trabajar directamente en el c√≥digo y explorar las visualizaciones en tiempo real!**

---

Este dise√±o utiliza un **badge de color verde brillante** con el logo de Google Colab, lo que har√° que se vea llamativo y visualmente atractivo. Adem√°s, se proporciona un mensaje claro y amigable para incentivar al usuario a hacer clic en el enlace.

¬°Pru√©balo y ver√°s c√≥mo resalta!


## üìä **M√©tricas de evaluaci√≥n**

| Indicador                                   | Valor / Observaci√≥n |
|---|---|
| **Modelo base (DummyClassifier) accuracy**   | 62% |
| **Logistic Regression accuracy**             | 78.5% |
| **F1-score (Logistic Regression)**           | 0.73 |
| **Confusion Matrix**                         | Basada en las predicciones del modelo |

**F1-Score** es una medida que equilibra la **precisi√≥n** (precision) y el **recall**. Para problemas de desbalance de clases, esta m√©trica es m√°s representativa que el **accuracy**.

---

## üìà **An√°lisis de la matriz de confusi√≥n**
La matriz de confusi√≥n muestra cu√°ntas veces el modelo predijo correctamente o incorrectamente cada clase:

- **Filas**: Clases reales (0 = No sobrevivi√≥, 1 = Sobrevivi√≥).
- **Columnas**: Clases predichas por el modelo.

### **Interpretemos la matriz:**
- **Falsos negativos (FN)**: Predicciones donde se dijo que no sobrevivieron cuando s√≠ lo hicieron.
- **Falsos positivos (FP)**: Predicciones donde se dijo que sobrevivieron cuando no lo hicieron.
  
El modelo comete m√°s **errores de falsos negativos** (es decir, no predecir que alguien sobrevivi√≥), lo que ser√≠a cr√≠tico en una situaci√≥n real de rescate.

---

## üß† **Preguntas para el equipo**

1. **¬øQu√© variables parecen m√°s relacionadas con la supervivencia?**
   - **Sexo:** Las mujeres tuvieron una tasa de supervivencia mucho mayor.
   - **Clase (Pclass):** Los pasajeros de 1¬™ clase tuvieron m√°s probabilidades de sobrevivir.
   - **Edad:** Los ni√±os y personas j√≥venes fueron priorizados en el rescate.

2. **¬øQu√© desaf√≠os de calidad de datos esperas encontrar?**
   - **Valores faltantes:** Especialmente en `Age` y `Cabin`. Usamos t√©cnicas de imputaci√≥n para los valores faltantes en `Age` y `Embarked`.
   - **Rango de datos inconsistente:** Aseguramos que todas las variables est√©n dentro de los rangos l√≥gicos.

3. **¬øQu√© variables podr√≠an estar correlacionadas?**
   - **Pclass y Fare:** Los pasajeros de primera clase pagaron tarifas m√°s altas y tienen mayor probabilidad de supervivencia.

---

## üí¨ **Reflexi√≥n**

Esta pr√°ctica mostr√≥ que el **Feature Engineering** mejora significativamente el rendimiento del modelo. El uso de variables como **FamilySize** y **Title** ayud√≥ a capturar informaci√≥n crucial sobre la supervivencia de los pasajeros.

## üõ† **Pr√≥ximos pasos**

- [x] Probar **otros modelos** como **Random Forest** y **KNN** para mejorar el rendimiento.
- [ ] Implementar **curvas ROC** y **m√©tricas por clase** para analizar el rendimiento m√°s a fondo.
- [ ] Experimentar con t√©cnicas avanzadas de **Feature Engineering** (por ejemplo, interacci√≥n de caracter√≠sticas).

---


## üßë‚Äçüíª **Reproducibilidad**

Para ejecutar este an√°lisis en tu m√°quina, aseg√∫rate de tener las librer√≠as necesarias:

```bash
pip install -q scikit-learn matplotlib seaborn
```

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.dummy import DummyClassifier

# Cargar datos
data = pd.read_csv('titanic.csv')

# Preprocesar datos y entrenar modelos
X = data[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]
y = data['Survived']
X = pd.get_dummies(X, drop_first=True)

# Divisi√≥n de datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Entrenamiento del DummyClassifier
dummy = DummyClassifier(strategy='most_frequent', random_state=42)
dummy.fit(X_train, y_train)
dummy_pred = dummy.predict(X_test)

# Entrenamiento de Logistic Regression
lr = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)
lr.fit(X_train, y_train)
lr_pred = lr.predict(X_test)

# Resultados
print('DummyClassifier Accuracy:', accuracy_score(y_test, dummy_pred))
print('Logistic Regression Accuracy:', accuracy_score(y_test, lr_pred))
```

---

## üí° **Conclusi√≥n**

Esta pr√°ctica no solo nos permiti√≥ aplicar **Feature Engineering** b√°sico, sino tambi√©n comprobar que incluso un modelo sencillo como **Regresi√≥n Log√≠stica** puede superar el modelo base, destacando la importancia de la ingenier√≠a de caracter√≠sticas en problemas de Machine Learning.
