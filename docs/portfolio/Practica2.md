# ğŸš€ **PrÃ¡ctica 2: Feature Engineering + Modelo Base**

![Titanic Banner](../assets/acerca/RMS_Titanic_3.jpg)

> âœ¨ *Aplicando ingenierÃ­a de caracterÃ­sticas y comparando modelos para predecir la supervivencia en el Titanic.*

---

## ğŸ·ï¸ **Etiquetas RÃ¡pidas**

`#2` `#Titanic` `#FeatureEngineering` `#MachineLearning` `#ModeloBase`

---

## ğŸš€ **Accesos Directos Importantes**

[![ğŸ“˜ Abrir Notebook en Google Colab](https://img.shields.io/badge/Abrir%20Notebook-Google%20Colab-brightgreen?style=for-the-badge&logo=googlecolab&logoColor=white)](https://colab.research.google.com/drive/1xOjYjaSN2DM7szuRU7wsep-l2vCXaDSR?usp=sharing)  
[![ğŸ“Š Ver Visualizaciones en Drive](https://img.shields.io/badge/Visualizaciones-Google%20Drive-blue?style=for-the-badge&logo=google-drive&logoColor=white)](https://drive.google.com/drive/folders/1WMHuuZMkUeXZYrEZBdhwqgbqwMg7vktG?usp=drive_link)

> âœ… *Haz clic en los botones para abrir el notebook y explorar las visualizaciones interactivas.*

---

---

## ğŸ§  **Resumen Ejecutivo**

ğŸ¯ **Objetivo:**  
Explorar y aplicar tÃ©cnicas de **Feature Engineering** sobre el dataset Titanic, entrenar un modelo de **RegresiÃ³n LogÃ­stica** y compararlo con un modelo base (**DummyClassifier**).

ğŸ“Œ **Hallazgos clave:**

- **Sexo** fue la variable mÃ¡s influyente.
- El modelo de **RegresiÃ³n LogÃ­stica** superÃ³ al DummyClassifier por amplio margen.
- Nuevas caracterÃ­sticas como `Title` y `FamilySize` mejoraron la predicciÃ³n.

ğŸ“ˆ **Resultado final:**  
Modelo con precisiÃ³n del **78.5%** y F1-score de **0.73**.

---

## ğŸ¯ **Objetivos EspecÃ­ficos**

| Objetivo                                                                 | Estado |
|--------------------------------------------------------------------------|--------|
| Aplicar Feature Engineering al dataset Titanic                           | âœ…      |
| Entrenar un modelo base (DummyClassifier)                                | âœ…      |
| Entrenar un modelo real (RegresiÃ³n LogÃ­stica)                            | âœ…      |
| Evaluar modelos con Accuracy, F1, Reporte de ClasificaciÃ³n y ConfusiÃ³n  | âœ…      |

---

## ğŸ“… **Actividades y Tiempos**

| Actividad                                       | Estimado | Real  | Nota                                                   |
|------------------------------------------------|----------|-------|--------------------------------------------------------|
| ConfiguraciÃ³n en Google Colab                  | 30 m     | 28 m  | Carga desde Kaggle                                     |
| Feature Engineering                            | 40 m     | 42 m  | Nuevas features + valores nulos                       |
| DummyClassifier (modelo base)                  | 20 m     | 22 m  | Estrategia: `most_frequent`                          |
| RegresiÃ³n LogÃ­stica                            | 30 m     | 35 m  | `liblinear` como solver                              |
| EvaluaciÃ³n de ambos modelos                    | 30 m     | 32 m  | Accuracy, F1, matriz de confusiÃ³n                     |
| ReflexiÃ³n final                                | 15 m     | 14 m  | AnÃ¡lisis de errores                                   |

ğŸ•’ **Total estimado:** 3 h Â· **Total real:** 3 h 13 m Â· Î”: +13 m (+6%)

---

## ğŸ› ï¸ **Feature Engineering Aplicado**

| TÃ©cnica                  | DescripciÃ³n                                                                 |
|--------------------------|------------------------------------------------------------------------------|
| **ImputaciÃ³n de valores**| - `Embarked`: modo<br>- `Fare`: mediana<br>- `Age`: mediana por `Sex` y `Pclass` |
| **Nuevas variables**     | - `FamilySize = SibSp + Parch + 1`<br>- `IsAlone = (FamilySize == 1)`       |
| **TÃ­tulos desde el nombre** | - ExtracciÃ³n de `Title` (`Mr`, `Mrs`, `Miss`, etc.)<br>- AgrupaciÃ³n en `Rare`     |

---

## âš™ï¸ **Modelos Entrenados**

### ğŸ”¹ **Modelo Base: DummyClassifier**

- **Estrategia:** `most_frequent`
- **Accuracy:** 62%
- **Rol:** Referencia para comparar modelos reales

### ğŸ”¸ **Modelo Real: RegresiÃ³n LogÃ­stica**

- **LibrerÃ­a:** `scikit-learn` (`LogisticRegression`)
- **Solver:** `liblinear`
- **Accuracy:** 78.5%
- **F1-Score:** 0.73

âœ… **Mejora significativa sobre el baseline**

---

## ğŸ“ˆ **MÃ©tricas de EvaluaciÃ³n**

| MÃ©trica                         | DummyClassifier | Logistic Regression |
|---------------------------------|------------------|----------------------|
| Accuracy                        | 62%             | **78.5%**            |
| F1-Score                        | â€”               | **0.73**             |
| Classification Report           | âŒ              | âœ…                   |
| Matriz de ConfusiÃ³n             | âŒ              | âœ…                   |

> â„¹ï¸ F1-score combina precisiÃ³n y recall, ideal en contextos con clases desbalanceadas.

---

## ğŸ“Š **Visualizaciones Relevantes**

### ğŸ¯ Matriz de ConfusiÃ³n - Logistic Regression

![imgP2.1](../../assets/ImgPractica2/imgP2.1.png)

- **AnÃ¡lisis:** El modelo comete mÃ¡s errores tipo **falso negativo**, es decir, no predice que alguien sobreviviÃ³ cuando sÃ­ lo hizo.

---

### ğŸ“ˆ ComparaciÃ³n de Accuracy

![imgP2.2](../../assets/ImgPractica2/imgP2.2.png)

> El modelo real supera claramente al DummyClassifier

---

## ğŸ“¸ **Explora Todas las Visualizaciones Interactivas**

[![ğŸ”— Ver Visualizaciones - Google Drive](https://img.shields.io/badge/Ver%20Visualizaciones-Google%20Drive-yellowgreen?style=for-the-badge&logo=google-drive&logoColor=white)](https://drive.google.com/drive/folders/1WMHuuZMkUeXZYrEZBdhwqgbqwMg7vktG?usp=drive_link)

> ğŸ–¼ï¸ *Mira las grÃ¡ficas generadas durante el anÃ¡lisis:*  
> Matrices de confusiÃ³n Â· Histogramas Â· Comparaciones de modelos Â· Distribuciones por sexo, clase, edad y mÃ¡s.

---

---

## ğŸ¤” **Preguntas para el Equipo**

---

### 1. Â¿QuÃ© variables aportaron mÃ¡s al modelo?

- `Sex`
- `Pclass`
- `Title`
- `Fare`
- `FamilySize`

---

### 2. Â¿QuÃ© desafÃ­os encontramos?

- ImputaciÃ³n de `Age` y valores nulos en `Embarked`.
- TransformaciÃ³n de variables categÃ³ricas con baja frecuencia.

---

### 3. Â¿QuÃ© variables podrÃ­an estar correlacionadas?

- `Pclass` â†”ï¸ `Fare`
- `IsAlone` â†”ï¸ `FamilySize`

---

## ğŸ” **ReflexiÃ³n Final**

ğŸ“Œ El uso de **Feature Engineering bÃ¡sico** incrementÃ³ la capacidad del modelo para distinguir entre pasajeros que sobrevivieron y los que no.  
ğŸ§  Variables como `Title` y `IsAlone` resultaron muy efectivas para captar relaciones no evidentes.

---

## ğŸ“Œ **Siguientes Pasos**

| PrÃ³xima AcciÃ³n                                       | Estado |
|------------------------------------------------------|--------|
| Probar modelos como **Random Forest**, **KNN**       | âœ…      |
| Usar curvas **ROC**, mÃ©tricas por clase              | ğŸ”œ      |
| Aplicar **GridSearchCV** para optimizar hiperparÃ¡metros | ğŸ”œ      |
| Explorar mÃ¡s tÃ©cnicas de Feature Engineering         | ğŸ”œ      |

---

## ğŸ§‘â€ğŸ’» **Reproducibilidad**

Para ejecutar este anÃ¡lisis en tu mÃ¡quina, asegÃºrate de tener las librerÃ­as necesarias:

```bash
pip install -q scikit-learn matplotlib seaborn
```

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.dummy import DummyClassifier

# Cargar datos
data = pd.read_csv('titanic.csv')

# Preprocesar datos y entrenar modelos
X = data[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]
y = data['Survived']
X = pd.get_dummies(X, drop_first=True)

# DivisiÃ³n de datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Entrenamiento del DummyClassifier
dummy = DummyClassifier(strategy='most_frequent', random_state=42)
dummy.fit(X_train, y_train)
dummy_pred = dummy.predict(X_test)

# Entrenamiento de Logistic Regression
lr = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)
lr.fit(X_train, y_train)
lr_pred = lr.predict(X_test)

# Resultados
print('DummyClassifier Accuracy:', accuracy_score(y_test, dummy_pred))
print('Logistic Regression Accuracy:', accuracy_score(y_test, lr_pred))
```

---

## ğŸ’¡ **ConclusiÃ³n**

Esta prÃ¡ctica no solo nos permitiÃ³ aplicar **Feature Engineering** bÃ¡sico, sino tambiÃ©n comprobar que incluso un modelo sencillo como **RegresiÃ³n LogÃ­stica** puede superar el modelo base, destacando la importancia de la ingenierÃ­a de caracterÃ­sticas en problemas de Machine Learning.
