---
title: "üìä Pr√°ctica 2: Feature Engineering + Modelo Base"
date: 2025-09-07
number: 2
status: "Completado"
tags: [Feature Engineering, Titanic, Machine Learning, Modelo Base]
notebook: https://colab.research.google.com/drive/1ut5NvjzklgNwS8wfOD07xslXUY7flhu4
drive_viz: https://drive.google.com/drive/folders/1qglTzvqdFPrNMxUhH_MtQFcRrafXEG7x?usp=sharing
dataset: "Titanic ‚Äî Kaggle"
time_est: "3 h"
time_spent: "‚Äî"
---

# üöÄ **Pr√°ctica 2: Feature Engineering + Modelo Base**

## üèÜ **Resumen ejecutivo**

En esta pr√°ctica, **trabajamos con el dataset Titanic**, aplicamos **Feature Engineering b√°sico** y entrenamos un modelo de **Regresi√≥n Log√≠stica**. Luego, comparamos el rendimiento del modelo con un **DummyClassifier** como baseline. 

**Objetivo:** Realizar un **an√°lisis exploratorio de caracter√≠sticas** y construir un modelo b√°sico.  
**Hallazgos clave:** La **variable 'Sexo'** es crucial para la supervivencia, y el **modelo de Regresi√≥n Log√≠stica** super√≥ ampliamente al **DummyClassifier**.  
**Resultado final:** El modelo base y los nuevos features mostraron mejoras en la predicci√≥n de la supervivencia.

---

## üéØ **Objetivos de la pr√°ctica**

- [x] Aplicar **Feature Engineering** para mejorar la informaci√≥n del dataset Titanic.  
- [x] Entrenar un **modelo base** usando **Regresi√≥n Log√≠stica**.  
- [x] Comparar el rendimiento entre un **modelo base** y un **modelo entrenado**.
- [x] **Evaluar** el modelo con m√©tricas como **accuracy**, **classification report**, y **confusion matrix**.

---

## ‚è±Ô∏è **Actividades y tiempos estimados**

| Actividad                                   | Estimado | Real | Nota |
|---|---:|---:|---|
| Configuraci√≥n inicial en **Google Colab**    | 30 m | **28 m** | Configuraci√≥n y carga de datos desde Kaggle. |
| Preprocesamiento y **Feature Engineering**   | 40 m | **42 m** | Manejo de valores faltantes y creaci√≥n de nuevas caracter√≠sticas. |
| Entrenamiento del **DummyClassifier**        | 20 m | **22 m** | Entrenamiento de un modelo base con la estrategia `most_frequent`. |
| **Entrenamiento de Regresi√≥n Log√≠stica**     | 30 m | **35 m** | Entrenamiento de modelo y optimizaci√≥n b√°sica de par√°metros. |
| Evaluaci√≥n de modelos y comparaci√≥n          | 30 m | **32 m** | Comparaci√≥n entre **DummyClassifier** y **Logistic Regression**. |
| Reflexi√≥n y discusi√≥n de preguntas           | 15 m | **14 m** | An√°lisis de errores y patrones en los datos. |

> **Totales** ‚Äî Estimado: **3 h** ¬∑ Real: **3 h 13 m** ¬∑ Œî: **+13 m** (**+6%**).

---

## üí° **Desarrollo: Feature Engineering**

### 1. **Manejo de valores faltantes:**
   - **Embarked:** Se reemplaza por el valor m√°s frecuente.
   - **Fare:** Se completa con la **mediana** de la tarifa.
   - **Age:** Se completa usando la **mediana** por grupo de `Sex` y `Pclass` para evitar sesgos.

### 2. **Creaci√≥n de nuevas caracter√≠sticas:**
   - **FamilySize:** La combinaci√≥n de `SibSp` (hermanos/esposos) y `Parch` (padres/hijos), para reflejar el tama√±o de la familia.
   - **IsAlone:** Una nueva variable que indica si el pasajero estaba solo (`FamilySize = 1`).
   - **Title:** Extracci√≥n del t√≠tulo del nombre (Sr, Mrs, Miss, etc.) para capturar categor√≠as de clase y edad.
   - **Rare Titles:** Agrupaci√≥n de t√≠tulos poco frecuentes bajo la categor√≠a 'Rare' para simplificar el modelo.

---

## üßë‚Äçüè´ **Modelo base vs Modelo entrenado**

### **Modelo base: DummyClassifier**
El **DummyClassifier** es un modelo muy simple que sirve como referencia b√°sica. En este caso, utilizamos la estrategia **most_frequent**, que predice siempre la clase m√°s frecuente (en este caso, que no sobrevivi√≥).

- **Accuracy:** 62%  
- **Prop√≥sito:** Ver qu√© tan bien lo hace un modelo "tonto" comparado con un modelo entrenado.

### **Modelo entrenado: Regresi√≥n Log√≠stica**
La **Regresi√≥n Log√≠stica** es un modelo muy com√∫n para problemas de clasificaci√≥n binaria. En este caso, usamos **LogisticRegression** de **scikit-learn** con un **solver liblinear** para optimizar los par√°metros.

- **Accuracy:** 78.5%  
- **F1-Score:** 0.73  
- **Mejora significativa sobre el DummyClassifier.**

---

## üìä **M√©tricas de evaluaci√≥n**

| Indicador                                   | Valor / Observaci√≥n |
|---|---|
| **Modelo base (DummyClassifier) accuracy**   | 62% |
| **Logistic Regression accuracy**             | 78.5% |
| **F1-score (Logistic Regression)**           | 0.73 |
| **Confusion Matrix**                         | Basada en las predicciones del modelo |

**F1-Score** es una medida que equilibra la **precisi√≥n** (precision) y el **recall**. Para problemas de desbalance de clases, esta m√©trica es m√°s representativa que el **accuracy**.

---

## üìà **An√°lisis de la matriz de confusi√≥n**
La matriz de confusi√≥n muestra cu√°ntas veces el modelo predijo correctamente o incorrectamente cada clase:

- **Filas**: Clases reales (0 = No sobrevivi√≥, 1 = Sobrevivi√≥).
- **Columnas**: Clases predichas por el modelo.

### **Interpretemos la matriz:**
- **Falsos negativos (FN)**: Predicciones donde se dijo que no sobrevivieron cuando s√≠ lo hicieron.
- **Falsos positivos (FP)**: Predicciones donde se dijo que sobrevivieron cuando no lo hicieron.
  
El modelo comete m√°s **errores de falsos negativos** (es decir, no predecir que alguien sobrevivi√≥), lo que ser√≠a cr√≠tico en una situaci√≥n real de rescate.

---

## üß† **Preguntas para el equipo**

1. **¬øQu√© variables parecen m√°s relacionadas con la supervivencia?**
   - **Sexo:** Las mujeres tuvieron una tasa de supervivencia mucho mayor.
   - **Clase (Pclass):** Los pasajeros de 1¬™ clase tuvieron m√°s probabilidades de sobrevivir.
   - **Edad:** Los ni√±os y personas j√≥venes fueron priorizados en el rescate.

2. **¬øQu√© desaf√≠os de calidad de datos esperas encontrar?**
   - **Valores faltantes:** Especialmente en `Age` y `Cabin`. Usamos t√©cnicas de imputaci√≥n para los valores faltantes en `Age` y `Embarked`.
   - **Rango de datos inconsistente:** Aseguramos que todas las variables est√©n dentro de los rangos l√≥gicos.

3. **¬øQu√© variables podr√≠an estar correlacionadas?**
   - **Pclass y Fare:** Los pasajeros de primera clase pagaron tarifas m√°s altas y tienen mayor probabilidad de supervivencia.

---

## üí¨ **Reflexi√≥n**

Esta pr√°ctica mostr√≥ que el **Feature Engineering** mejora significativamente el rendimiento del modelo. El uso de variables como **FamilySize** y **Title** ayud√≥ a capturar informaci√≥n crucial sobre la supervivencia de los pasajeros.

## üõ† **Pr√≥ximos pasos**

- [x] Probar **otros modelos** como **Random Forest** y **KNN** para mejorar el rendimiento.
- [ ] Implementar **curvas ROC** y **m√©tricas por clase** para analizar el rendimiento m√°s a fondo.
- [ ] Experimentar con t√©cnicas avanzadas de **Feature Engineering** (por ejemplo, interacci√≥n de caracter√≠sticas).

---

## üßë‚Äçüíª **Reproducibilidad**

Para ejecutar este an√°lisis en tu m√°quina, aseg√∫rate de tener las librer√≠as necesarias:

```bash
pip install -q scikit-learn matplotlib seaborn
```

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.dummy import DummyClassifier

# Cargar datos
data = pd.read_csv('titanic.csv')

# Preprocesar datos y entrenar modelos
X = data[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]
y = data['Survived']
X = pd.get_dummies(X, drop_first=True)

# Divisi√≥n de datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Entrenamiento del DummyClassifier
dummy = DummyClassifier(strategy='most_frequent', random_state=42)
dummy.fit(X_train, y_train)
dummy_pred = dummy.predict(X_test)

# Entrenamiento de Logistic Regression
lr = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)
lr.fit(X_train, y_train)
lr_pred = lr.predict(X_test)

# Resultados
print('DummyClassifier Accuracy:', accuracy_score(y_test, dummy_pred))
print('Logistic Regression Accuracy:', accuracy_score(y_test, lr_pred))
```

---

## üí° **Conclusi√≥n**

Esta pr√°ctica no solo nos permiti√≥ aplicar **Feature Engineering** b√°sico, sino tambi√©n comprobar que incluso un modelo sencillo como **Regresi√≥n Log√≠stica** puede superar el modelo base, destacando la importancia de la ingenier√≠a de caracter√≠sticas en problemas de Machine Learning.
